{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e0bb6c0",
   "metadata": {},
   "source": [
    "# Drug Activity Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5116ce",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6635f4a5",
   "metadata": {},
   "source": [
    "The goal of this project is to allow us to develop predictive models that can determine given a particular compound whether it is active (1) or not (0). As such, the goal would be developing the best binary classification model. A molecule can be represented by 100000 binary features which represent their topological shapes and other characteristics important for binding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f14e23cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing basic libraries \n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fabf3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C has no label.\n",
      " Volume Serial Number is 96F3-7600\n",
      "\n",
      " Directory of C:\\Users\\Beauty\\Documents\\INeuron\\Project_1\\Drug-Activity-Prediction-Dorothea-Dataset-master\n",
      "\n",
      "27-09-2022  22:41    <DIR>          .\n",
      "27-09-2022  22:41    <DIR>          ..\n",
      "27-09-2022  10:57    <DIR>          .ipynb_checkpoints\n",
      "27-09-2022  22:36             2,870 application.py\n",
      "27-09-2022  11:14             6,190 demo.xlsx\n",
      "27-09-2022  11:16             5,144 demo_csv.csv\n",
      "30-08-2022  12:20           256,742 Drug_Activity_Prediction_1.ipynb\n",
      "04-09-2022  18:58           258,368 Drug_Activity_Prediction_2.ipynb\n",
      "04-09-2022  16:27           234,058 Drug_Activity_Prediction_3.ipynb\n",
      "04-09-2022  19:21           195,587 Drug_Activity_Prediction_4.ipynb\n",
      "04-09-2022  21:23           160,196 Drug_Activity_Prediction_5.ipynb\n",
      "27-09-2022  22:41           293,347 Drug_Activity_Prediction_final.ipynb\n",
      "27-09-2022  11:12            11,040 dt.sav\n",
      "23-08-2022  09:03             6,502 PR2 - Drug Activity Prediction.ipynb\n",
      "26-08-2022  11:33             6,190 Target_variable.xlsx\n",
      "23-08-2022  11:13         3,253,849 TEST.csv\n",
      "27-06-2018  07:47         1,871,651 test.dat\n",
      "23-08-2022  11:10             6,190 test_data.xlsx\n",
      "23-08-2022  11:39         8,409,679 TRAIN.csv\n",
      "27-06-2018  07:47         4,288,639 train.dat\n",
      "23-08-2022  11:09             6,190 train_data.xlsx\n",
      "30-08-2022  19:49             1,644 Trial_3.ipynb\n",
      "27-06-2018  07:47               699 valid_labels.dat\n",
      "26-08-2022  11:35             1,050 Y.csv\n",
      "              21 File(s)     19,275,825 bytes\n",
      "               3 Dir(s)  117,512,769,536 bytes free\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2824cc",
   "metadata": {},
   "source": [
    "# Step-1: Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4e18952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the training data\n",
    "train_data = pd.read_csv('TRAIN.csv',header=None)\n",
    "train_X = train_data.iloc[:,1:]\n",
    "train_Y = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0214ffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "795    0\n",
       "796    0\n",
       "797    0\n",
       "798    0\n",
       "799    1\n",
       "Name: Y, Length: 800, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y.rename('Y',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a79ab5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>6052</th>\n",
       "      <th>6053</th>\n",
       "      <th>6054</th>\n",
       "      <th>6055</th>\n",
       "      <th>6056</th>\n",
       "      <th>6057</th>\n",
       "      <th>6058</th>\n",
       "      <th>6059</th>\n",
       "      <th>6060</th>\n",
       "      <th>6061</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191</td>\n",
       "      <td>367</td>\n",
       "      <td>614</td>\n",
       "      <td>634</td>\n",
       "      <td>711</td>\n",
       "      <td>1202</td>\n",
       "      <td>1220</td>\n",
       "      <td>1311</td>\n",
       "      <td>1472</td>\n",
       "      <td>1730</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>307</td>\n",
       "      <td>367</td>\n",
       "      <td>478</td>\n",
       "      <td>505</td>\n",
       "      <td>512</td>\n",
       "      <td>807</td>\n",
       "      <td>878</td>\n",
       "      <td>939</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>184</td>\n",
       "      <td>284</td>\n",
       "      <td>297</td>\n",
       "      <td>320</td>\n",
       "      <td>375</td>\n",
       "      <td>445</td>\n",
       "      <td>588</td>\n",
       "      <td>658</td>\n",
       "      <td>1108</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>149</td>\n",
       "      <td>433</td>\n",
       "      <td>704</td>\n",
       "      <td>711</td>\n",
       "      <td>892</td>\n",
       "      <td>988</td>\n",
       "      <td>1056</td>\n",
       "      <td>1070</td>\n",
       "      <td>1234</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>118</td>\n",
       "      <td>279</td>\n",
       "      <td>316</td>\n",
       "      <td>435</td>\n",
       "      <td>505</td>\n",
       "      <td>584</td>\n",
       "      <td>629</td>\n",
       "      <td>849</td>\n",
       "      <td>1029</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>374</td>\n",
       "      <td>1031</td>\n",
       "      <td>1271</td>\n",
       "      <td>1312</td>\n",
       "      <td>1452</td>\n",
       "      <td>1517</td>\n",
       "      <td>1628</td>\n",
       "      <td>1668</td>\n",
       "      <td>1898</td>\n",
       "      <td>1958</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>106</td>\n",
       "      <td>465</td>\n",
       "      <td>1095</td>\n",
       "      <td>1119</td>\n",
       "      <td>1176</td>\n",
       "      <td>1658</td>\n",
       "      <td>1669</td>\n",
       "      <td>1679</td>\n",
       "      <td>1813</td>\n",
       "      <td>1889</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>140</td>\n",
       "      <td>273</td>\n",
       "      <td>303</td>\n",
       "      <td>354</td>\n",
       "      <td>383</td>\n",
       "      <td>436</td>\n",
       "      <td>619</td>\n",
       "      <td>640</td>\n",
       "      <td>798</td>\n",
       "      <td>866</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>126</td>\n",
       "      <td>150</td>\n",
       "      <td>354</td>\n",
       "      <td>377</td>\n",
       "      <td>379</td>\n",
       "      <td>702</td>\n",
       "      <td>764</td>\n",
       "      <td>1099</td>\n",
       "      <td>1110</td>\n",
       "      <td>1220</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>354</td>\n",
       "      <td>412</td>\n",
       "      <td>425</td>\n",
       "      <td>433</td>\n",
       "      <td>783</td>\n",
       "      <td>915</td>\n",
       "      <td>1070</td>\n",
       "      <td>1642</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 6061 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1     2     3     4     5     6     7     8     9     10    ...  6052  \\\n",
       "0     191   367   614   634   711  1202  1220  1311  1472  1730  ...   NaN   \n",
       "1     118   307   367   478   505   512   807   878   939  1024  ...   NaN   \n",
       "2      10   184   284   297   320   375   445   588   658  1108  ...   NaN   \n",
       "3      87   149   433   704   711   892   988  1056  1070  1234  ...   NaN   \n",
       "4      84   118   279   316   435   505   584   629   849  1029  ...   NaN   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "795   374  1031  1271  1312  1452  1517  1628  1668  1898  1958  ...   NaN   \n",
       "796   106   465  1095  1119  1176  1658  1669  1679  1813  1889  ...   NaN   \n",
       "797   140   273   303   354   383   436   619   640   798   866  ...   NaN   \n",
       "798   126   150   354   377   379   702   764  1099  1110  1220  ...   NaN   \n",
       "799   190   191   354   412   425   433   783   915  1070  1642  ...   NaN   \n",
       "\n",
       "     6053  6054  6055  6056  6057  6058  6059  6060  6061  \n",
       "0     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "795   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "796   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "797   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "798   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "799   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[800 rows x 6061 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the testing data\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b98179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6051</th>\n",
       "      <th>6052</th>\n",
       "      <th>6053</th>\n",
       "      <th>6054</th>\n",
       "      <th>6055</th>\n",
       "      <th>6056</th>\n",
       "      <th>6057</th>\n",
       "      <th>6058</th>\n",
       "      <th>6059</th>\n",
       "      <th>6060</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191</td>\n",
       "      <td>367</td>\n",
       "      <td>614</td>\n",
       "      <td>634</td>\n",
       "      <td>711</td>\n",
       "      <td>1202</td>\n",
       "      <td>1220</td>\n",
       "      <td>1311</td>\n",
       "      <td>1472</td>\n",
       "      <td>1730</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>307</td>\n",
       "      <td>367</td>\n",
       "      <td>478</td>\n",
       "      <td>505</td>\n",
       "      <td>512</td>\n",
       "      <td>807</td>\n",
       "      <td>878</td>\n",
       "      <td>939</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>184</td>\n",
       "      <td>284</td>\n",
       "      <td>297</td>\n",
       "      <td>320</td>\n",
       "      <td>375</td>\n",
       "      <td>445</td>\n",
       "      <td>588</td>\n",
       "      <td>658</td>\n",
       "      <td>1108</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>149</td>\n",
       "      <td>433</td>\n",
       "      <td>704</td>\n",
       "      <td>711</td>\n",
       "      <td>892</td>\n",
       "      <td>988</td>\n",
       "      <td>1056</td>\n",
       "      <td>1070</td>\n",
       "      <td>1234</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>118</td>\n",
       "      <td>279</td>\n",
       "      <td>316</td>\n",
       "      <td>435</td>\n",
       "      <td>505</td>\n",
       "      <td>584</td>\n",
       "      <td>629</td>\n",
       "      <td>849</td>\n",
       "      <td>1029</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>374</td>\n",
       "      <td>1031</td>\n",
       "      <td>1271</td>\n",
       "      <td>1312</td>\n",
       "      <td>1452</td>\n",
       "      <td>1517</td>\n",
       "      <td>1628</td>\n",
       "      <td>1668</td>\n",
       "      <td>1898</td>\n",
       "      <td>1958</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>106</td>\n",
       "      <td>465</td>\n",
       "      <td>1095</td>\n",
       "      <td>1119</td>\n",
       "      <td>1176</td>\n",
       "      <td>1658</td>\n",
       "      <td>1669</td>\n",
       "      <td>1679</td>\n",
       "      <td>1813</td>\n",
       "      <td>1889</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>140</td>\n",
       "      <td>273</td>\n",
       "      <td>303</td>\n",
       "      <td>354</td>\n",
       "      <td>383</td>\n",
       "      <td>436</td>\n",
       "      <td>619</td>\n",
       "      <td>640</td>\n",
       "      <td>798</td>\n",
       "      <td>866</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>126</td>\n",
       "      <td>150</td>\n",
       "      <td>354</td>\n",
       "      <td>377</td>\n",
       "      <td>379</td>\n",
       "      <td>702</td>\n",
       "      <td>764</td>\n",
       "      <td>1099</td>\n",
       "      <td>1110</td>\n",
       "      <td>1220</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>354</td>\n",
       "      <td>412</td>\n",
       "      <td>425</td>\n",
       "      <td>433</td>\n",
       "      <td>783</td>\n",
       "      <td>915</td>\n",
       "      <td>1070</td>\n",
       "      <td>1642</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 6061 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     ...  6051  \\\n",
       "0     191   367   614   634   711  1202  1220  1311  1472  1730  ...   NaN   \n",
       "1     118   307   367   478   505   512   807   878   939  1024  ...   NaN   \n",
       "2      10   184   284   297   320   375   445   588   658  1108  ...   NaN   \n",
       "3      87   149   433   704   711   892   988  1056  1070  1234  ...   NaN   \n",
       "4      84   118   279   316   435   505   584   629   849  1029  ...   NaN   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "795   374  1031  1271  1312  1452  1517  1628  1668  1898  1958  ...   NaN   \n",
       "796   106   465  1095  1119  1176  1658  1669  1679  1813  1889  ...   NaN   \n",
       "797   140   273   303   354   383   436   619   640   798   866  ...   NaN   \n",
       "798   126   150   354   377   379   702   764  1099  1110  1220  ...   NaN   \n",
       "799   190   191   354   412   425   433   783   915  1070  1642  ...   NaN   \n",
       "\n",
       "     6052  6053  6054  6055  6056  6057  6058  6059  6060  \n",
       "0     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "795   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "796   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "797   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "798   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "799   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[800 rows x 6061 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the column names of the train dataset to start from 0\n",
    "for i in train_X.columns:\n",
    "    train_X.rename(columns={i:(i-1)},inplace=True)\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adda51a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>4847</th>\n",
       "      <th>4848</th>\n",
       "      <th>4849</th>\n",
       "      <th>4850</th>\n",
       "      <th>4851</th>\n",
       "      <th>4852</th>\n",
       "      <th>4853</th>\n",
       "      <th>4854</th>\n",
       "      <th>4855</th>\n",
       "      <th>4856</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>354</td>\n",
       "      <td>386</td>\n",
       "      <td>517</td>\n",
       "      <td>627</td>\n",
       "      <td>646</td>\n",
       "      <td>764</td>\n",
       "      <td>870</td>\n",
       "      <td>915</td>\n",
       "      <td>1364</td>\n",
       "      <td>1502</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>225</td>\n",
       "      <td>360</td>\n",
       "      <td>394</td>\n",
       "      <td>433</td>\n",
       "      <td>445</td>\n",
       "      <td>1021</td>\n",
       "      <td>1205</td>\n",
       "      <td>1861</td>\n",
       "      <td>2036</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103</td>\n",
       "      <td>144</td>\n",
       "      <td>284</td>\n",
       "      <td>309</td>\n",
       "      <td>393</td>\n",
       "      <td>843</td>\n",
       "      <td>915</td>\n",
       "      <td>936</td>\n",
       "      <td>983</td>\n",
       "      <td>1183</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>174</td>\n",
       "      <td>300</td>\n",
       "      <td>307</td>\n",
       "      <td>430</td>\n",
       "      <td>523</td>\n",
       "      <td>546</td>\n",
       "      <td>616</td>\n",
       "      <td>861</td>\n",
       "      <td>1108</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>585</td>\n",
       "      <td>767</td>\n",
       "      <td>783</td>\n",
       "      <td>1176</td>\n",
       "      <td>1214</td>\n",
       "      <td>1224</td>\n",
       "      <td>1256</td>\n",
       "      <td>1303</td>\n",
       "      <td>1605</td>\n",
       "      <td>2102</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>280</td>\n",
       "      <td>316</td>\n",
       "      <td>462</td>\n",
       "      <td>486</td>\n",
       "      <td>549</td>\n",
       "      <td>588</td>\n",
       "      <td>1048</td>\n",
       "      <td>1115</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>87</td>\n",
       "      <td>144</td>\n",
       "      <td>157</td>\n",
       "      <td>334</td>\n",
       "      <td>336</td>\n",
       "      <td>548</td>\n",
       "      <td>581</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>56</td>\n",
       "      <td>61</td>\n",
       "      <td>91</td>\n",
       "      <td>106</td>\n",
       "      <td>321</td>\n",
       "      <td>478</td>\n",
       "      <td>540</td>\n",
       "      <td>688</td>\n",
       "      <td>781</td>\n",
       "      <td>816</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>9</td>\n",
       "      <td>191</td>\n",
       "      <td>378</td>\n",
       "      <td>379</td>\n",
       "      <td>436</td>\n",
       "      <td>482</td>\n",
       "      <td>575</td>\n",
       "      <td>613</td>\n",
       "      <td>766</td>\n",
       "      <td>914</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>69</td>\n",
       "      <td>183</td>\n",
       "      <td>369</td>\n",
       "      <td>400</td>\n",
       "      <td>474</td>\n",
       "      <td>833</td>\n",
       "      <td>848</td>\n",
       "      <td>1186</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 4857 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     ...  4847  \\\n",
       "0     354   386   517   627   646   764   870   915  1364  1502  ...   NaN   \n",
       "1      23   225   360   394   433   445  1021  1205  1861  2036  ...   NaN   \n",
       "2     103   144   284   309   393   843   915   936   983  1183  ...   NaN   \n",
       "3      13   174   300   307   430   523   546   616   861  1108  ...   NaN   \n",
       "4     585   767   783  1176  1214  1224  1256  1303  1605  2102  ...   NaN   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "345    43    50   280   316   462   486   549   588  1048  1115  ...   NaN   \n",
       "346    24    26    30    87   144   157   334   336   548   581  ...   NaN   \n",
       "347    56    61    91   106   321   478   540   688   781   816  ...   NaN   \n",
       "348     9   191   378   379   436   482   575   613   766   914  ...   NaN   \n",
       "349    10    56    69   183   369   400   474   833   848  1186  ...   NaN   \n",
       "\n",
       "     4848  4849  4850  4851  4852  4853  4854  4855  4856  \n",
       "0     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "345   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "346   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "347   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "348   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "349   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[350 rows x 4857 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv('TEST.csv',header=None)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca62a994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily Combining train and test data for ease of data preprocessing\n",
    "df = pd.concat([train_X,test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaf08e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>6051</th>\n",
       "      <th>6052</th>\n",
       "      <th>6053</th>\n",
       "      <th>6054</th>\n",
       "      <th>6055</th>\n",
       "      <th>6056</th>\n",
       "      <th>6057</th>\n",
       "      <th>6058</th>\n",
       "      <th>6059</th>\n",
       "      <th>6060</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191</td>\n",
       "      <td>367</td>\n",
       "      <td>614</td>\n",
       "      <td>634</td>\n",
       "      <td>711</td>\n",
       "      <td>1202</td>\n",
       "      <td>1220</td>\n",
       "      <td>1311</td>\n",
       "      <td>1472</td>\n",
       "      <td>1730</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>307</td>\n",
       "      <td>367</td>\n",
       "      <td>478</td>\n",
       "      <td>505</td>\n",
       "      <td>512</td>\n",
       "      <td>807</td>\n",
       "      <td>878</td>\n",
       "      <td>939</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>184</td>\n",
       "      <td>284</td>\n",
       "      <td>297</td>\n",
       "      <td>320</td>\n",
       "      <td>375</td>\n",
       "      <td>445</td>\n",
       "      <td>588</td>\n",
       "      <td>658</td>\n",
       "      <td>1108</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>149</td>\n",
       "      <td>433</td>\n",
       "      <td>704</td>\n",
       "      <td>711</td>\n",
       "      <td>892</td>\n",
       "      <td>988</td>\n",
       "      <td>1056</td>\n",
       "      <td>1070</td>\n",
       "      <td>1234</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>118</td>\n",
       "      <td>279</td>\n",
       "      <td>316</td>\n",
       "      <td>435</td>\n",
       "      <td>505</td>\n",
       "      <td>584</td>\n",
       "      <td>629</td>\n",
       "      <td>849</td>\n",
       "      <td>1029</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>280</td>\n",
       "      <td>316</td>\n",
       "      <td>462</td>\n",
       "      <td>486</td>\n",
       "      <td>549</td>\n",
       "      <td>588</td>\n",
       "      <td>1048</td>\n",
       "      <td>1115</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>87</td>\n",
       "      <td>144</td>\n",
       "      <td>157</td>\n",
       "      <td>334</td>\n",
       "      <td>336</td>\n",
       "      <td>548</td>\n",
       "      <td>581</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>56</td>\n",
       "      <td>61</td>\n",
       "      <td>91</td>\n",
       "      <td>106</td>\n",
       "      <td>321</td>\n",
       "      <td>478</td>\n",
       "      <td>540</td>\n",
       "      <td>688</td>\n",
       "      <td>781</td>\n",
       "      <td>816</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>9</td>\n",
       "      <td>191</td>\n",
       "      <td>378</td>\n",
       "      <td>379</td>\n",
       "      <td>436</td>\n",
       "      <td>482</td>\n",
       "      <td>575</td>\n",
       "      <td>613</td>\n",
       "      <td>766</td>\n",
       "      <td>914</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>69</td>\n",
       "      <td>183</td>\n",
       "      <td>369</td>\n",
       "      <td>400</td>\n",
       "      <td>474</td>\n",
       "      <td>833</td>\n",
       "      <td>848</td>\n",
       "      <td>1186</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1150 rows × 6061 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2     3     4     5     6     7     8     9     ...  6051  \\\n",
       "0     191   367   614   634   711  1202  1220  1311  1472  1730  ...   NaN   \n",
       "1     118   307   367   478   505   512   807   878   939  1024  ...   NaN   \n",
       "2      10   184   284   297   320   375   445   588   658  1108  ...   NaN   \n",
       "3      87   149   433   704   711   892   988  1056  1070  1234  ...   NaN   \n",
       "4      84   118   279   316   435   505   584   629   849  1029  ...   NaN   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "345    43    50   280   316   462   486   549   588  1048  1115  ...   NaN   \n",
       "346    24    26    30    87   144   157   334   336   548   581  ...   NaN   \n",
       "347    56    61    91   106   321   478   540   688   781   816  ...   NaN   \n",
       "348     9   191   378   379   436   482   575   613   766   914  ...   NaN   \n",
       "349    10    56    69   183   369   400   474   833   848  1186  ...   NaN   \n",
       "\n",
       "     6052  6053  6054  6055  6056  6057  6058  6059  6060  \n",
       "0     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "1     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "2     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "3     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "4     NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "345   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "346   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "347   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "348   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "349   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN   NaN  \n",
       "\n",
       "[1150 rows x 6061 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8216d9",
   "metadata": {},
   "source": [
    "# Step-2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95cbdf76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>718</th>\n",
       "      <th>719</th>\n",
       "      <th>720</th>\n",
       "      <th>721</th>\n",
       "      <th>722</th>\n",
       "      <th>723</th>\n",
       "      <th>724</th>\n",
       "      <th>725</th>\n",
       "      <th>726</th>\n",
       "      <th>727</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191</td>\n",
       "      <td>367</td>\n",
       "      <td>614</td>\n",
       "      <td>634</td>\n",
       "      <td>711</td>\n",
       "      <td>1202</td>\n",
       "      <td>1220</td>\n",
       "      <td>1311</td>\n",
       "      <td>1472</td>\n",
       "      <td>1730</td>\n",
       "      <td>...</td>\n",
       "      <td>93972.0</td>\n",
       "      <td>94210.0</td>\n",
       "      <td>94211.0</td>\n",
       "      <td>94226.0</td>\n",
       "      <td>94493.0</td>\n",
       "      <td>94583.0</td>\n",
       "      <td>94611.0</td>\n",
       "      <td>94618.0</td>\n",
       "      <td>94715.0</td>\n",
       "      <td>95145.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118</td>\n",
       "      <td>307</td>\n",
       "      <td>367</td>\n",
       "      <td>478</td>\n",
       "      <td>505</td>\n",
       "      <td>512</td>\n",
       "      <td>807</td>\n",
       "      <td>878</td>\n",
       "      <td>939</td>\n",
       "      <td>1024</td>\n",
       "      <td>...</td>\n",
       "      <td>99610.0</td>\n",
       "      <td>99626.0</td>\n",
       "      <td>99731.0</td>\n",
       "      <td>99938.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>184</td>\n",
       "      <td>284</td>\n",
       "      <td>297</td>\n",
       "      <td>320</td>\n",
       "      <td>375</td>\n",
       "      <td>445</td>\n",
       "      <td>588</td>\n",
       "      <td>658</td>\n",
       "      <td>1108</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87</td>\n",
       "      <td>149</td>\n",
       "      <td>433</td>\n",
       "      <td>704</td>\n",
       "      <td>711</td>\n",
       "      <td>892</td>\n",
       "      <td>988</td>\n",
       "      <td>1056</td>\n",
       "      <td>1070</td>\n",
       "      <td>1234</td>\n",
       "      <td>...</td>\n",
       "      <td>98230.0</td>\n",
       "      <td>98316.0</td>\n",
       "      <td>98827.0</td>\n",
       "      <td>98881.0</td>\n",
       "      <td>98994.0</td>\n",
       "      <td>99091.0</td>\n",
       "      <td>99169.0</td>\n",
       "      <td>99257.0</td>\n",
       "      <td>99317.0</td>\n",
       "      <td>99426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84</td>\n",
       "      <td>118</td>\n",
       "      <td>279</td>\n",
       "      <td>316</td>\n",
       "      <td>435</td>\n",
       "      <td>505</td>\n",
       "      <td>584</td>\n",
       "      <td>629</td>\n",
       "      <td>849</td>\n",
       "      <td>1029</td>\n",
       "      <td>...</td>\n",
       "      <td>90336.0</td>\n",
       "      <td>90440.0</td>\n",
       "      <td>90745.0</td>\n",
       "      <td>90831.0</td>\n",
       "      <td>91187.0</td>\n",
       "      <td>91496.0</td>\n",
       "      <td>91737.0</td>\n",
       "      <td>91812.0</td>\n",
       "      <td>91826.0</td>\n",
       "      <td>91971.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>280</td>\n",
       "      <td>316</td>\n",
       "      <td>462</td>\n",
       "      <td>486</td>\n",
       "      <td>549</td>\n",
       "      <td>588</td>\n",
       "      <td>1048</td>\n",
       "      <td>1115</td>\n",
       "      <td>...</td>\n",
       "      <td>98184.0</td>\n",
       "      <td>98356.0</td>\n",
       "      <td>98458.0</td>\n",
       "      <td>98680.0</td>\n",
       "      <td>98769.0</td>\n",
       "      <td>98789.0</td>\n",
       "      <td>98812.0</td>\n",
       "      <td>98908.0</td>\n",
       "      <td>98909.0</td>\n",
       "      <td>98938.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>30</td>\n",
       "      <td>87</td>\n",
       "      <td>144</td>\n",
       "      <td>157</td>\n",
       "      <td>334</td>\n",
       "      <td>336</td>\n",
       "      <td>548</td>\n",
       "      <td>581</td>\n",
       "      <td>...</td>\n",
       "      <td>95288.0</td>\n",
       "      <td>95304.0</td>\n",
       "      <td>95331.0</td>\n",
       "      <td>95337.0</td>\n",
       "      <td>95392.0</td>\n",
       "      <td>95472.0</td>\n",
       "      <td>95729.0</td>\n",
       "      <td>95932.0</td>\n",
       "      <td>95997.0</td>\n",
       "      <td>96034.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>56</td>\n",
       "      <td>61</td>\n",
       "      <td>91</td>\n",
       "      <td>106</td>\n",
       "      <td>321</td>\n",
       "      <td>478</td>\n",
       "      <td>540</td>\n",
       "      <td>688</td>\n",
       "      <td>781</td>\n",
       "      <td>816</td>\n",
       "      <td>...</td>\n",
       "      <td>95829.0</td>\n",
       "      <td>95951.0</td>\n",
       "      <td>96235.0</td>\n",
       "      <td>96377.0</td>\n",
       "      <td>96468.0</td>\n",
       "      <td>96493.0</td>\n",
       "      <td>96586.0</td>\n",
       "      <td>96832.0</td>\n",
       "      <td>96853.0</td>\n",
       "      <td>97016.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>9</td>\n",
       "      <td>191</td>\n",
       "      <td>378</td>\n",
       "      <td>379</td>\n",
       "      <td>436</td>\n",
       "      <td>482</td>\n",
       "      <td>575</td>\n",
       "      <td>613</td>\n",
       "      <td>766</td>\n",
       "      <td>914</td>\n",
       "      <td>...</td>\n",
       "      <td>73597.0</td>\n",
       "      <td>73601.0</td>\n",
       "      <td>73656.0</td>\n",
       "      <td>73754.0</td>\n",
       "      <td>73937.0</td>\n",
       "      <td>74206.0</td>\n",
       "      <td>74250.0</td>\n",
       "      <td>74282.0</td>\n",
       "      <td>74575.0</td>\n",
       "      <td>74594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>69</td>\n",
       "      <td>183</td>\n",
       "      <td>369</td>\n",
       "      <td>400</td>\n",
       "      <td>474</td>\n",
       "      <td>833</td>\n",
       "      <td>848</td>\n",
       "      <td>1186</td>\n",
       "      <td>...</td>\n",
       "      <td>99837.0</td>\n",
       "      <td>99956.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1150 rows × 728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4     5     6     7     8     9    ...      718  \\\n",
       "0    191  367  614  634  711  1202  1220  1311  1472  1730  ...  93972.0   \n",
       "1    118  307  367  478  505   512   807   878   939  1024  ...  99610.0   \n",
       "2     10  184  284  297  320   375   445   588   658  1108  ...      NaN   \n",
       "3     87  149  433  704  711   892   988  1056  1070  1234  ...  98230.0   \n",
       "4     84  118  279  316  435   505   584   629   849  1029  ...  90336.0   \n",
       "..   ...  ...  ...  ...  ...   ...   ...   ...   ...   ...  ...      ...   \n",
       "345   43   50  280  316  462   486   549   588  1048  1115  ...  98184.0   \n",
       "346   24   26   30   87  144   157   334   336   548   581  ...  95288.0   \n",
       "347   56   61   91  106  321   478   540   688   781   816  ...  95829.0   \n",
       "348    9  191  378  379  436   482   575   613   766   914  ...  73597.0   \n",
       "349   10   56   69  183  369   400   474   833   848  1186  ...  99837.0   \n",
       "\n",
       "         719      720      721      722      723      724      725      726  \\\n",
       "0    94210.0  94211.0  94226.0  94493.0  94583.0  94611.0  94618.0  94715.0   \n",
       "1    99626.0  99731.0  99938.0      NaN      NaN      NaN      NaN      NaN   \n",
       "2        NaN      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "3    98316.0  98827.0  98881.0  98994.0  99091.0  99169.0  99257.0  99317.0   \n",
       "4    90440.0  90745.0  90831.0  91187.0  91496.0  91737.0  91812.0  91826.0   \n",
       "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "345  98356.0  98458.0  98680.0  98769.0  98789.0  98812.0  98908.0  98909.0   \n",
       "346  95304.0  95331.0  95337.0  95392.0  95472.0  95729.0  95932.0  95997.0   \n",
       "347  95951.0  96235.0  96377.0  96468.0  96493.0  96586.0  96832.0  96853.0   \n",
       "348  73601.0  73656.0  73754.0  73937.0  74206.0  74250.0  74282.0  74575.0   \n",
       "349  99956.0      NaN      NaN      NaN      NaN      NaN      NaN      NaN   \n",
       "\n",
       "         727  \n",
       "0    95145.0  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3    99426.0  \n",
       "4    91971.0  \n",
       "..       ...  \n",
       "345  98938.0  \n",
       "346  96034.0  \n",
       "347  97016.0  \n",
       "348  74594.0  \n",
       "349      NaN  \n",
       "\n",
       "[1150 rows x 728 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing all the columns for which the Nan values are greater than 15% of total train data\n",
    "\n",
    "for col in df.columns:\n",
    "    if df[col].isna().sum()> 0.15*(df.shape[0]):\n",
    "        df.drop(columns=col,inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd02c178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "      ... \n",
       "723    143\n",
       "724    150\n",
       "725    155\n",
       "726    161\n",
       "727    171\n",
       "Length: 728, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for null values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0942227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.91000000e+02 3.67000000e+02 6.14000000e+02 ... 9.46180000e+04\n",
      "  9.47150000e+04 9.51450000e+04]\n",
      " [1.18000000e+02 3.07000000e+02 3.67000000e+02 ... 8.36310362e+04\n",
      "  8.36504762e+04 8.35998917e+04]\n",
      " [1.00000000e+01 1.84000000e+02 2.84000000e+02 ... 8.36310362e+04\n",
      "  8.36504762e+04 8.35998917e+04]\n",
      " ...\n",
      " [5.60000000e+01 6.10000000e+01 9.10000000e+01 ... 9.68320000e+04\n",
      "  9.68530000e+04 9.70160000e+04]\n",
      " [9.00000000e+00 1.91000000e+02 3.78000000e+02 ... 7.42820000e+04\n",
      "  7.45750000e+04 7.45940000e+04]\n",
      " [1.00000000e+01 5.60000000e+01 6.90000000e+01 ... 8.36310362e+04\n",
      "  8.36504762e+04 8.35998917e+04]]\n"
     ]
    }
   ],
   "source": [
    "# Replacing the null values with the Mean of that feature\n",
    "B = df\n",
    "imputer = SimpleImputer(missing_values=np.nan,strategy='mean')\n",
    "imputer = imputer.fit(B)\n",
    "B = imputer.transform(B)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c51ca66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>718</th>\n",
       "      <th>719</th>\n",
       "      <th>720</th>\n",
       "      <th>721</th>\n",
       "      <th>722</th>\n",
       "      <th>723</th>\n",
       "      <th>724</th>\n",
       "      <th>725</th>\n",
       "      <th>726</th>\n",
       "      <th>727</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>191.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>614.0</td>\n",
       "      <td>634.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>1202.0</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>1472.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93972.000000</td>\n",
       "      <td>94210.000000</td>\n",
       "      <td>94211.000000</td>\n",
       "      <td>94226.000000</td>\n",
       "      <td>94493.000000</td>\n",
       "      <td>94583.000000</td>\n",
       "      <td>94611.000</td>\n",
       "      <td>94618.000000</td>\n",
       "      <td>94715.000000</td>\n",
       "      <td>95145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>118.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>807.0</td>\n",
       "      <td>878.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>1024.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99610.000000</td>\n",
       "      <td>99626.000000</td>\n",
       "      <td>99731.000000</td>\n",
       "      <td>99938.000000</td>\n",
       "      <td>83615.141732</td>\n",
       "      <td>83590.648461</td>\n",
       "      <td>83594.089</td>\n",
       "      <td>83631.036181</td>\n",
       "      <td>83650.476239</td>\n",
       "      <td>83599.891726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>375.0</td>\n",
       "      <td>445.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>658.0</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>...</td>\n",
       "      <td>83622.011472</td>\n",
       "      <td>83705.043103</td>\n",
       "      <td>83697.896718</td>\n",
       "      <td>83657.714425</td>\n",
       "      <td>83615.141732</td>\n",
       "      <td>83590.648461</td>\n",
       "      <td>83594.089</td>\n",
       "      <td>83631.036181</td>\n",
       "      <td>83650.476239</td>\n",
       "      <td>83599.891726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>87.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>433.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>892.0</td>\n",
       "      <td>988.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>1070.0</td>\n",
       "      <td>1234.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98230.000000</td>\n",
       "      <td>98316.000000</td>\n",
       "      <td>98827.000000</td>\n",
       "      <td>98881.000000</td>\n",
       "      <td>98994.000000</td>\n",
       "      <td>99091.000000</td>\n",
       "      <td>99169.000</td>\n",
       "      <td>99257.000000</td>\n",
       "      <td>99317.000000</td>\n",
       "      <td>99426.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>435.0</td>\n",
       "      <td>505.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>629.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>1029.0</td>\n",
       "      <td>...</td>\n",
       "      <td>90336.000000</td>\n",
       "      <td>90440.000000</td>\n",
       "      <td>90745.000000</td>\n",
       "      <td>90831.000000</td>\n",
       "      <td>91187.000000</td>\n",
       "      <td>91496.000000</td>\n",
       "      <td>91737.000</td>\n",
       "      <td>91812.000000</td>\n",
       "      <td>91826.000000</td>\n",
       "      <td>91971.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>43.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>316.0</td>\n",
       "      <td>462.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>588.0</td>\n",
       "      <td>1048.0</td>\n",
       "      <td>1115.0</td>\n",
       "      <td>...</td>\n",
       "      <td>98184.000000</td>\n",
       "      <td>98356.000000</td>\n",
       "      <td>98458.000000</td>\n",
       "      <td>98680.000000</td>\n",
       "      <td>98769.000000</td>\n",
       "      <td>98789.000000</td>\n",
       "      <td>98812.000</td>\n",
       "      <td>98908.000000</td>\n",
       "      <td>98909.000000</td>\n",
       "      <td>98938.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1146</th>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95288.000000</td>\n",
       "      <td>95304.000000</td>\n",
       "      <td>95331.000000</td>\n",
       "      <td>95337.000000</td>\n",
       "      <td>95392.000000</td>\n",
       "      <td>95472.000000</td>\n",
       "      <td>95729.000</td>\n",
       "      <td>95932.000000</td>\n",
       "      <td>95997.000000</td>\n",
       "      <td>96034.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>56.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>478.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>688.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>816.0</td>\n",
       "      <td>...</td>\n",
       "      <td>95829.000000</td>\n",
       "      <td>95951.000000</td>\n",
       "      <td>96235.000000</td>\n",
       "      <td>96377.000000</td>\n",
       "      <td>96468.000000</td>\n",
       "      <td>96493.000000</td>\n",
       "      <td>96586.000</td>\n",
       "      <td>96832.000000</td>\n",
       "      <td>96853.000000</td>\n",
       "      <td>97016.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1148</th>\n",
       "      <td>9.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>436.0</td>\n",
       "      <td>482.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>914.0</td>\n",
       "      <td>...</td>\n",
       "      <td>73597.000000</td>\n",
       "      <td>73601.000000</td>\n",
       "      <td>73656.000000</td>\n",
       "      <td>73754.000000</td>\n",
       "      <td>73937.000000</td>\n",
       "      <td>74206.000000</td>\n",
       "      <td>74250.000</td>\n",
       "      <td>74282.000000</td>\n",
       "      <td>74575.000000</td>\n",
       "      <td>74594.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>10.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>474.0</td>\n",
       "      <td>833.0</td>\n",
       "      <td>848.0</td>\n",
       "      <td>1186.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99837.000000</td>\n",
       "      <td>99956.000000</td>\n",
       "      <td>83697.896718</td>\n",
       "      <td>83657.714425</td>\n",
       "      <td>83615.141732</td>\n",
       "      <td>83590.648461</td>\n",
       "      <td>83594.089</td>\n",
       "      <td>83631.036181</td>\n",
       "      <td>83650.476239</td>\n",
       "      <td>83599.891726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1150 rows × 728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1      2      3      4       5       6       7       8    \\\n",
       "0     191.0  367.0  614.0  634.0  711.0  1202.0  1220.0  1311.0  1472.0   \n",
       "1     118.0  307.0  367.0  478.0  505.0   512.0   807.0   878.0   939.0   \n",
       "2      10.0  184.0  284.0  297.0  320.0   375.0   445.0   588.0   658.0   \n",
       "3      87.0  149.0  433.0  704.0  711.0   892.0   988.0  1056.0  1070.0   \n",
       "4      84.0  118.0  279.0  316.0  435.0   505.0   584.0   629.0   849.0   \n",
       "...     ...    ...    ...    ...    ...     ...     ...     ...     ...   \n",
       "1145   43.0   50.0  280.0  316.0  462.0   486.0   549.0   588.0  1048.0   \n",
       "1146   24.0   26.0   30.0   87.0  144.0   157.0   334.0   336.0   548.0   \n",
       "1147   56.0   61.0   91.0  106.0  321.0   478.0   540.0   688.0   781.0   \n",
       "1148    9.0  191.0  378.0  379.0  436.0   482.0   575.0   613.0   766.0   \n",
       "1149   10.0   56.0   69.0  183.0  369.0   400.0   474.0   833.0   848.0   \n",
       "\n",
       "         9    ...           718           719           720           721  \\\n",
       "0     1730.0  ...  93972.000000  94210.000000  94211.000000  94226.000000   \n",
       "1     1024.0  ...  99610.000000  99626.000000  99731.000000  99938.000000   \n",
       "2     1108.0  ...  83622.011472  83705.043103  83697.896718  83657.714425   \n",
       "3     1234.0  ...  98230.000000  98316.000000  98827.000000  98881.000000   \n",
       "4     1029.0  ...  90336.000000  90440.000000  90745.000000  90831.000000   \n",
       "...      ...  ...           ...           ...           ...           ...   \n",
       "1145  1115.0  ...  98184.000000  98356.000000  98458.000000  98680.000000   \n",
       "1146   581.0  ...  95288.000000  95304.000000  95331.000000  95337.000000   \n",
       "1147   816.0  ...  95829.000000  95951.000000  96235.000000  96377.000000   \n",
       "1148   914.0  ...  73597.000000  73601.000000  73656.000000  73754.000000   \n",
       "1149  1186.0  ...  99837.000000  99956.000000  83697.896718  83657.714425   \n",
       "\n",
       "               722           723        724           725           726  \\\n",
       "0     94493.000000  94583.000000  94611.000  94618.000000  94715.000000   \n",
       "1     83615.141732  83590.648461  83594.089  83631.036181  83650.476239   \n",
       "2     83615.141732  83590.648461  83594.089  83631.036181  83650.476239   \n",
       "3     98994.000000  99091.000000  99169.000  99257.000000  99317.000000   \n",
       "4     91187.000000  91496.000000  91737.000  91812.000000  91826.000000   \n",
       "...            ...           ...        ...           ...           ...   \n",
       "1145  98769.000000  98789.000000  98812.000  98908.000000  98909.000000   \n",
       "1146  95392.000000  95472.000000  95729.000  95932.000000  95997.000000   \n",
       "1147  96468.000000  96493.000000  96586.000  96832.000000  96853.000000   \n",
       "1148  73937.000000  74206.000000  74250.000  74282.000000  74575.000000   \n",
       "1149  83615.141732  83590.648461  83594.089  83631.036181  83650.476239   \n",
       "\n",
       "               727  \n",
       "0     95145.000000  \n",
       "1     83599.891726  \n",
       "2     83599.891726  \n",
       "3     99426.000000  \n",
       "4     91971.000000  \n",
       "...            ...  \n",
       "1145  98938.000000  \n",
       "1146  96034.000000  \n",
       "1147  97016.000000  \n",
       "1148  74594.000000  \n",
       "1149  83599.891726  \n",
       "\n",
       "[1150 rows x 728 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nonna = pd.DataFrame(B)\n",
    "df_nonna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03a80ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "723    0\n",
       "724    0\n",
       "725    0\n",
       "726    0\n",
       "727    0\n",
       "Length: 728, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nonna.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fef3a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_nonna = scaler.fit_transform(df_nonna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c149f419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting Training and Testing Scaled Data\n",
    "\n",
    "train_data_final = pd.DataFrame(df_nonna[:800,:])\n",
    "test_data_final = pd.DataFrame(df_nonna[800:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "762ce622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>718</th>\n",
       "      <th>719</th>\n",
       "      <th>720</th>\n",
       "      <th>721</th>\n",
       "      <th>722</th>\n",
       "      <th>723</th>\n",
       "      <th>724</th>\n",
       "      <th>725</th>\n",
       "      <th>726</th>\n",
       "      <th>727</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.641830</td>\n",
       "      <td>0.840012</td>\n",
       "      <td>1.309415</td>\n",
       "      <td>0.746270</td>\n",
       "      <td>0.464911</td>\n",
       "      <td>1.527357</td>\n",
       "      <td>1.054324</td>\n",
       "      <td>0.900028</td>\n",
       "      <td>0.922056</td>\n",
       "      <td>1.138531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649158</td>\n",
       "      <td>0.658627</td>\n",
       "      <td>0.660642</td>\n",
       "      <td>0.666273</td>\n",
       "      <td>6.880474e-01</td>\n",
       "      <td>0.697227</td>\n",
       "      <td>0.700193</td>\n",
       "      <td>0.699012</td>\n",
       "      <td>0.705148</td>\n",
       "      <td>0.738403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.029789</td>\n",
       "      <td>0.472837</td>\n",
       "      <td>0.111022</td>\n",
       "      <td>0.105894</td>\n",
       "      <td>-0.246011</td>\n",
       "      <td>-0.561246</td>\n",
       "      <td>-0.043600</td>\n",
       "      <td>-0.161026</td>\n",
       "      <td>-0.293540</td>\n",
       "      <td>-0.361082</td>\n",
       "      <td>...</td>\n",
       "      <td>1.002777</td>\n",
       "      <td>0.998193</td>\n",
       "      <td>1.007518</td>\n",
       "      <td>1.026384</td>\n",
       "      <td>-9.204392e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.875696</td>\n",
       "      <td>-0.279873</td>\n",
       "      <td>-0.291677</td>\n",
       "      <td>-0.637106</td>\n",
       "      <td>-0.884461</td>\n",
       "      <td>-0.975940</td>\n",
       "      <td>-1.005946</td>\n",
       "      <td>-0.871662</td>\n",
       "      <td>-0.934408</td>\n",
       "      <td>-0.182658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.204392e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.230119</td>\n",
       "      <td>-0.494059</td>\n",
       "      <td>0.431240</td>\n",
       "      <td>1.033619</td>\n",
       "      <td>0.464911</td>\n",
       "      <td>0.588999</td>\n",
       "      <td>0.437572</td>\n",
       "      <td>0.275158</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.084979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916222</td>\n",
       "      <td>0.916060</td>\n",
       "      <td>0.950710</td>\n",
       "      <td>0.959746</td>\n",
       "      <td>9.727451e-01</td>\n",
       "      <td>0.983163</td>\n",
       "      <td>0.989883</td>\n",
       "      <td>0.994154</td>\n",
       "      <td>0.998435</td>\n",
       "      <td>1.012208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.255271</td>\n",
       "      <td>-0.683766</td>\n",
       "      <td>-0.315936</td>\n",
       "      <td>-0.559112</td>\n",
       "      <td>-0.487587</td>\n",
       "      <td>-0.582435</td>\n",
       "      <td>-0.636426</td>\n",
       "      <td>-0.771193</td>\n",
       "      <td>-0.498800</td>\n",
       "      <td>-0.350461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.421106</td>\n",
       "      <td>0.422260</td>\n",
       "      <td>0.442839</td>\n",
       "      <td>0.452237</td>\n",
       "      <td>4.789359e-01</td>\n",
       "      <td>0.501424</td>\n",
       "      <td>0.517533</td>\n",
       "      <td>0.520488</td>\n",
       "      <td>0.521030</td>\n",
       "      <td>0.535400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>2.176124</td>\n",
       "      <td>4.903422</td>\n",
       "      <td>4.497045</td>\n",
       "      <td>3.529444</td>\n",
       "      <td>3.022162</td>\n",
       "      <td>2.480850</td>\n",
       "      <td>2.138956</td>\n",
       "      <td>1.774846</td>\n",
       "      <td>1.893621</td>\n",
       "      <td>1.622825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.204392e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>-0.070820</td>\n",
       "      <td>1.439733</td>\n",
       "      <td>3.643129</td>\n",
       "      <td>2.737183</td>\n",
       "      <td>2.069664</td>\n",
       "      <td>2.907652</td>\n",
       "      <td>2.247951</td>\n",
       "      <td>1.801801</td>\n",
       "      <td>1.699764</td>\n",
       "      <td>1.476263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811730</td>\n",
       "      <td>0.806466</td>\n",
       "      <td>0.817176</td>\n",
       "      <td>0.827037</td>\n",
       "      <td>8.452288e-01</td>\n",
       "      <td>0.852437</td>\n",
       "      <td>0.862897</td>\n",
       "      <td>0.864365</td>\n",
       "      <td>0.886142</td>\n",
       "      <td>0.897787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>0.214240</td>\n",
       "      <td>0.264771</td>\n",
       "      <td>-0.199493</td>\n",
       "      <td>-0.403123</td>\n",
       "      <td>-0.667043</td>\n",
       "      <td>-0.791295</td>\n",
       "      <td>-0.543382</td>\n",
       "      <td>-0.744238</td>\n",
       "      <td>-0.615114</td>\n",
       "      <td>-0.696689</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.306472</td>\n",
       "      <td>-1.305977</td>\n",
       "      <td>-1.292986</td>\n",
       "      <td>-1.292837</td>\n",
       "      <td>-1.292945e+00</td>\n",
       "      <td>-1.287638</td>\n",
       "      <td>-1.288036</td>\n",
       "      <td>-1.288346</td>\n",
       "      <td>-1.291720</td>\n",
       "      <td>-1.275318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>0.096862</td>\n",
       "      <td>-0.487939</td>\n",
       "      <td>0.047948</td>\n",
       "      <td>-0.308708</td>\n",
       "      <td>-0.680847</td>\n",
       "      <td>0.013877</td>\n",
       "      <td>-0.157912</td>\n",
       "      <td>0.380528</td>\n",
       "      <td>0.096454</td>\n",
       "      <td>0.055241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375131</td>\n",
       "      <td>0.377244</td>\n",
       "      <td>0.383581</td>\n",
       "      <td>0.391525</td>\n",
       "      <td>3.962022e-01</td>\n",
       "      <td>0.404505</td>\n",
       "      <td>0.408915</td>\n",
       "      <td>0.420284</td>\n",
       "      <td>0.426072</td>\n",
       "      <td>0.431341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>0.633446</td>\n",
       "      <td>-0.237036</td>\n",
       "      <td>0.047948</td>\n",
       "      <td>-0.165034</td>\n",
       "      <td>-0.522097</td>\n",
       "      <td>-0.800376</td>\n",
       "      <td>-0.107402</td>\n",
       "      <td>-0.070358</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.951610</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746249</td>\n",
       "      <td>0.768472</td>\n",
       "      <td>0.794239</td>\n",
       "      <td>0.799675</td>\n",
       "      <td>8.086691e-01</td>\n",
       "      <td>0.823069</td>\n",
       "      <td>0.842114</td>\n",
       "      <td>0.844897</td>\n",
       "      <td>0.858611</td>\n",
       "      <td>0.869134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.641830  0.840012  1.309415  0.746270  0.464911  1.527357  1.054324   \n",
       "1    0.029789  0.472837  0.111022  0.105894 -0.246011 -0.561246 -0.043600   \n",
       "2   -0.875696 -0.279873 -0.291677 -0.637106 -0.884461 -0.975940 -1.005946   \n",
       "3   -0.230119 -0.494059  0.431240  1.033619  0.464911  0.588999  0.437572   \n",
       "4   -0.255271 -0.683766 -0.315936 -0.559112 -0.487587 -0.582435 -0.636426   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "795  2.176124  4.903422  4.497045  3.529444  3.022162  2.480850  2.138956   \n",
       "796 -0.070820  1.439733  3.643129  2.737183  2.069664  2.907652  2.247951   \n",
       "797  0.214240  0.264771 -0.199493 -0.403123 -0.667043 -0.791295 -0.543382   \n",
       "798  0.096862 -0.487939  0.047948 -0.308708 -0.680847  0.013877 -0.157912   \n",
       "799  0.633446 -0.237036  0.047948 -0.165034 -0.522097 -0.800376 -0.107402   \n",
       "\n",
       "          7         8         9    ...       718       719       720  \\\n",
       "0    0.900028  0.922056  1.138531  ...  0.649158  0.658627  0.660642   \n",
       "1   -0.161026 -0.293540 -0.361082  ...  1.002777  0.998193  1.007518   \n",
       "2   -0.871662 -0.934408 -0.182658  ...  0.000000  0.000000  0.000000   \n",
       "3    0.275158  0.005228  0.084979  ...  0.916222  0.916060  0.950710   \n",
       "4   -0.771193 -0.498800 -0.350461  ...  0.421106  0.422260  0.442839   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "795  1.774846  1.893621  1.622825  ...  0.000000  0.000000  0.000000   \n",
       "796  1.801801  1.699764  1.476263  ...  0.811730  0.806466  0.817176   \n",
       "797 -0.744238 -0.615114 -0.696689  ... -1.306472 -1.305977 -1.292986   \n",
       "798  0.380528  0.096454  0.055241  ...  0.375131  0.377244  0.383581   \n",
       "799 -0.070358  0.005228  0.951610  ...  0.746249  0.768472  0.794239   \n",
       "\n",
       "          721           722       723       724       725       726       727  \n",
       "0    0.666273  6.880474e-01  0.697227  0.700193  0.699012  0.705148  0.738403  \n",
       "1    1.026384 -9.204392e-16  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2    0.000000 -9.204392e-16  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3    0.959746  9.727451e-01  0.983163  0.989883  0.994154  0.998435  1.012208  \n",
       "4    0.452237  4.789359e-01  0.501424  0.517533  0.520488  0.521030  0.535400  \n",
       "..        ...           ...       ...       ...       ...       ...       ...  \n",
       "795  0.000000 -9.204392e-16  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "796  0.827037  8.452288e-01  0.852437  0.862897  0.864365  0.886142  0.897787  \n",
       "797 -1.292837 -1.292945e+00 -1.287638 -1.288036 -1.288346 -1.291720 -1.275318  \n",
       "798  0.391525  3.962022e-01  0.404505  0.408915  0.420284  0.426072  0.431341  \n",
       "799  0.799675  8.086691e-01  0.823069  0.842114  0.844897  0.858611  0.869134  \n",
       "\n",
       "[800 rows x 728 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1af5292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>718</th>\n",
       "      <th>719</th>\n",
       "      <th>720</th>\n",
       "      <th>721</th>\n",
       "      <th>722</th>\n",
       "      <th>723</th>\n",
       "      <th>724</th>\n",
       "      <th>725</th>\n",
       "      <th>726</th>\n",
       "      <th>727</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.008441</td>\n",
       "      <td>0.956285</td>\n",
       "      <td>0.838791</td>\n",
       "      <td>0.717535</td>\n",
       "      <td>0.240591</td>\n",
       "      <td>0.201548</td>\n",
       "      <td>0.123880</td>\n",
       "      <td>-0.070358</td>\n",
       "      <td>0.675744</td>\n",
       "      <td>0.654237</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.085238</td>\n",
       "      <td>-0.037495</td>\n",
       "      <td>-0.036692</td>\n",
       "      <td>-0.021417</td>\n",
       "      <td>-1.696053e-02</td>\n",
       "      <td>0.032498</td>\n",
       "      <td>0.037556</td>\n",
       "      <td>0.037725</td>\n",
       "      <td>0.038590</td>\n",
       "      <td>0.051173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.766702</td>\n",
       "      <td>-0.028970</td>\n",
       "      <td>0.077059</td>\n",
       "      <td>-0.238924</td>\n",
       "      <td>-0.494489</td>\n",
       "      <td>-0.764052</td>\n",
       "      <td>0.525300</td>\n",
       "      <td>0.640278</td>\n",
       "      <td>1.809236</td>\n",
       "      <td>1.788505</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407746</td>\n",
       "      <td>0.406273</td>\n",
       "      <td>0.410288</td>\n",
       "      <td>0.425884</td>\n",
       "      <td>4.312438e-01</td>\n",
       "      <td>0.438376</td>\n",
       "      <td>0.447875</td>\n",
       "      <td>0.449041</td>\n",
       "      <td>0.453540</td>\n",
       "      <td>0.461976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.095973</td>\n",
       "      <td>-0.524657</td>\n",
       "      <td>-0.291677</td>\n",
       "      <td>-0.587847</td>\n",
       "      <td>-0.632532</td>\n",
       "      <td>0.440678</td>\n",
       "      <td>0.243508</td>\n",
       "      <td>-0.018898</td>\n",
       "      <td>-0.193190</td>\n",
       "      <td>-0.023350</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.470988</td>\n",
       "      <td>-1.471246</td>\n",
       "      <td>-1.454044</td>\n",
       "      <td>-1.448494</td>\n",
       "      <td>-1.440323e+00</td>\n",
       "      <td>-1.441515</td>\n",
       "      <td>-1.440508</td>\n",
       "      <td>-1.440529</td>\n",
       "      <td>-1.429569</td>\n",
       "      <td>-1.414683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.850543</td>\n",
       "      <td>-0.341069</td>\n",
       "      <td>-0.214049</td>\n",
       "      <td>-0.596057</td>\n",
       "      <td>-0.504842</td>\n",
       "      <td>-0.527949</td>\n",
       "      <td>-0.737446</td>\n",
       "      <td>-0.803049</td>\n",
       "      <td>-0.471432</td>\n",
       "      <td>-0.182658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823208</td>\n",
       "      <td>0.835996</td>\n",
       "      <td>0.839170</td>\n",
       "      <td>0.856857</td>\n",
       "      <td>8.700237e-01</td>\n",
       "      <td>0.885610</td>\n",
       "      <td>0.887303</td>\n",
       "      <td>0.923024</td>\n",
       "      <td>0.926739</td>\n",
       "      <td>0.941918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.945173</td>\n",
       "      <td>3.287849</td>\n",
       "      <td>2.129369</td>\n",
       "      <td>2.971167</td>\n",
       "      <td>2.200805</td>\n",
       "      <td>1.593950</td>\n",
       "      <td>1.150027</td>\n",
       "      <td>0.880424</td>\n",
       "      <td>1.225385</td>\n",
       "      <td>1.928695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950280</td>\n",
       "      <td>0.949603</td>\n",
       "      <td>0.963907</td>\n",
       "      <td>0.973804</td>\n",
       "      <td>9.909617e-01</td>\n",
       "      <td>1.033652</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-0.599020</td>\n",
       "      <td>-1.099898</td>\n",
       "      <td>-0.311084</td>\n",
       "      <td>-0.559112</td>\n",
       "      <td>-0.394407</td>\n",
       "      <td>-0.639947</td>\n",
       "      <td>-0.729471</td>\n",
       "      <td>-0.871662</td>\n",
       "      <td>-0.044947</td>\n",
       "      <td>-0.167789</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913337</td>\n",
       "      <td>0.918568</td>\n",
       "      <td>0.927522</td>\n",
       "      <td>0.947074</td>\n",
       "      <td>9.585133e-01</td>\n",
       "      <td>0.964007</td>\n",
       "      <td>0.967193</td>\n",
       "      <td>0.971950</td>\n",
       "      <td>0.972433</td>\n",
       "      <td>0.980997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-0.758318</td>\n",
       "      <td>-1.246768</td>\n",
       "      <td>-1.524033</td>\n",
       "      <td>-1.499151</td>\n",
       "      <td>-1.491851</td>\n",
       "      <td>-1.635817</td>\n",
       "      <td>-1.301029</td>\n",
       "      <td>-1.489180</td>\n",
       "      <td>-1.185281</td>\n",
       "      <td>-1.302057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731698</td>\n",
       "      <td>0.727217</td>\n",
       "      <td>0.731022</td>\n",
       "      <td>0.736316</td>\n",
       "      <td>7.449110e-01</td>\n",
       "      <td>0.753615</td>\n",
       "      <td>0.771249</td>\n",
       "      <td>0.782611</td>\n",
       "      <td>0.786850</td>\n",
       "      <td>0.795262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-0.490026</td>\n",
       "      <td>-1.032583</td>\n",
       "      <td>-1.228074</td>\n",
       "      <td>-1.421157</td>\n",
       "      <td>-0.881010</td>\n",
       "      <td>-0.664163</td>\n",
       "      <td>-0.753396</td>\n",
       "      <td>-0.626615</td>\n",
       "      <td>-0.653885</td>\n",
       "      <td>-0.802894</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765630</td>\n",
       "      <td>0.767782</td>\n",
       "      <td>0.787830</td>\n",
       "      <td>0.801882</td>\n",
       "      <td>8.129703e-01</td>\n",
       "      <td>0.818376</td>\n",
       "      <td>0.825717</td>\n",
       "      <td>0.839870</td>\n",
       "      <td>0.841403</td>\n",
       "      <td>0.858069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>-0.884080</td>\n",
       "      <td>-0.237036</td>\n",
       "      <td>0.164391</td>\n",
       "      <td>-0.300498</td>\n",
       "      <td>-0.484135</td>\n",
       "      <td>-0.652055</td>\n",
       "      <td>-0.660352</td>\n",
       "      <td>-0.810400</td>\n",
       "      <td>-0.688095</td>\n",
       "      <td>-0.594733</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.628775</td>\n",
       "      <td>-0.633491</td>\n",
       "      <td>-0.631031</td>\n",
       "      <td>-0.624375</td>\n",
       "      <td>-6.121628e-01</td>\n",
       "      <td>-0.595253</td>\n",
       "      <td>-0.593875</td>\n",
       "      <td>-0.594803</td>\n",
       "      <td>-0.578385</td>\n",
       "      <td>-0.576000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-0.875696</td>\n",
       "      <td>-1.063181</td>\n",
       "      <td>-1.334813</td>\n",
       "      <td>-1.105074</td>\n",
       "      <td>-0.715358</td>\n",
       "      <td>-0.900266</td>\n",
       "      <td>-0.928852</td>\n",
       "      <td>-0.271297</td>\n",
       "      <td>-0.501081</td>\n",
       "      <td>-0.016978</td>\n",
       "      <td>...</td>\n",
       "      <td>1.017014</td>\n",
       "      <td>1.018883</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.204392e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    2.008441  0.956285  0.838791  0.717535  0.240591  0.201548  0.123880   \n",
       "1   -0.766702 -0.028970  0.077059 -0.238924 -0.494489 -0.764052  0.525300   \n",
       "2   -0.095973 -0.524657 -0.291677 -0.587847 -0.632532  0.440678  0.243508   \n",
       "3   -0.850543 -0.341069 -0.214049 -0.596057 -0.504842 -0.527949 -0.737446   \n",
       "4    3.945173  3.287849  2.129369  2.971167  2.200805  1.593950  1.150027   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "345 -0.599020 -1.099898 -0.311084 -0.559112 -0.394407 -0.639947 -0.729471   \n",
       "346 -0.758318 -1.246768 -1.524033 -1.499151 -1.491851 -1.635817 -1.301029   \n",
       "347 -0.490026 -1.032583 -1.228074 -1.421157 -0.881010 -0.664163 -0.753396   \n",
       "348 -0.884080 -0.237036  0.164391 -0.300498 -0.484135 -0.652055 -0.660352   \n",
       "349 -0.875696 -1.063181 -1.334813 -1.105074 -0.715358 -0.900266 -0.928852   \n",
       "\n",
       "          7         8         9    ...       718       719       720  \\\n",
       "0   -0.070358  0.675744  0.654237  ... -0.085238 -0.037495 -0.036692   \n",
       "1    0.640278  1.809236  1.788505  ...  0.407746  0.406273  0.410288   \n",
       "2   -0.018898 -0.193190 -0.023350  ... -1.470988 -1.471246 -1.454044   \n",
       "3   -0.803049 -0.471432 -0.182658  ...  0.823208  0.835996  0.839170   \n",
       "4    0.880424  1.225385  1.928695  ...  0.950280  0.949603  0.963907   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "345 -0.871662 -0.044947 -0.167789  ...  0.913337  0.918568  0.927522   \n",
       "346 -1.489180 -1.185281 -1.302057  ...  0.731698  0.727217  0.731022   \n",
       "347 -0.626615 -0.653885 -0.802894  ...  0.765630  0.767782  0.787830   \n",
       "348 -0.810400 -0.688095 -0.594733  ... -0.628775 -0.633491 -0.631031   \n",
       "349 -0.271297 -0.501081 -0.016978  ...  1.017014  1.018883  0.000000   \n",
       "\n",
       "          721           722       723       724       725       726       727  \n",
       "0   -0.021417 -1.696053e-02  0.032498  0.037556  0.037725  0.038590  0.051173  \n",
       "1    0.425884  4.312438e-01  0.438376  0.447875  0.449041  0.453540  0.461976  \n",
       "2   -1.448494 -1.440323e+00 -1.441515 -1.440508 -1.440529 -1.429569 -1.414683  \n",
       "3    0.856857  8.700237e-01  0.885610  0.887303  0.923024  0.926739  0.941918  \n",
       "4    0.973804  9.909617e-01  1.033652  0.000000  0.000000  0.000000  0.000000  \n",
       "..        ...           ...       ...       ...       ...       ...       ...  \n",
       "345  0.947074  9.585133e-01  0.964007  0.967193  0.971950  0.972433  0.980997  \n",
       "346  0.736316  7.449110e-01  0.753615  0.771249  0.782611  0.786850  0.795262  \n",
       "347  0.801882  8.129703e-01  0.818376  0.825717  0.839870  0.841403  0.858069  \n",
       "348 -0.624375 -6.121628e-01 -0.595253 -0.593875 -0.594803 -0.578385 -0.576000  \n",
       "349  0.000000 -9.204392e-16  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[350 rows x 728 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0bbd81",
   "metadata": {},
   "source": [
    "# Dimension Reduction using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38a5a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reducing the features to 100\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "train_pca = pca.fit_transform(train_data_final)\n",
    "test_pca = pca.transform(test_data_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2630f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_F = pd.concat([pd.DataFrame(train_pca[:,:100]),train_Y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4239c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16.679750</td>\n",
       "      <td>6.610424</td>\n",
       "      <td>1.136733</td>\n",
       "      <td>-1.577995</td>\n",
       "      <td>0.941055</td>\n",
       "      <td>-3.025814</td>\n",
       "      <td>-1.121022</td>\n",
       "      <td>2.277669</td>\n",
       "      <td>-0.086481</td>\n",
       "      <td>0.151895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003830</td>\n",
       "      <td>-0.008588</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>-0.079178</td>\n",
       "      <td>0.063324</td>\n",
       "      <td>0.101782</td>\n",
       "      <td>0.006377</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>0.022819</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-23.458153</td>\n",
       "      <td>-1.462552</td>\n",
       "      <td>0.568286</td>\n",
       "      <td>0.682060</td>\n",
       "      <td>2.939810</td>\n",
       "      <td>1.185212</td>\n",
       "      <td>0.878989</td>\n",
       "      <td>0.180153</td>\n",
       "      <td>1.651810</td>\n",
       "      <td>1.065205</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029080</td>\n",
       "      <td>0.092626</td>\n",
       "      <td>-0.011072</td>\n",
       "      <td>-0.094988</td>\n",
       "      <td>0.163561</td>\n",
       "      <td>-0.030005</td>\n",
       "      <td>0.168839</td>\n",
       "      <td>0.143847</td>\n",
       "      <td>0.098675</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.483531</td>\n",
       "      <td>-1.381947</td>\n",
       "      <td>-5.211168</td>\n",
       "      <td>-0.556892</td>\n",
       "      <td>1.478389</td>\n",
       "      <td>0.592714</td>\n",
       "      <td>-0.714275</td>\n",
       "      <td>1.184789</td>\n",
       "      <td>-1.722228</td>\n",
       "      <td>-0.758348</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.116402</td>\n",
       "      <td>-0.028197</td>\n",
       "      <td>0.288280</td>\n",
       "      <td>0.067875</td>\n",
       "      <td>0.111195</td>\n",
       "      <td>-0.101227</td>\n",
       "      <td>0.089442</td>\n",
       "      <td>-0.193335</td>\n",
       "      <td>0.005820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-15.449717</td>\n",
       "      <td>-1.581954</td>\n",
       "      <td>2.722015</td>\n",
       "      <td>3.208696</td>\n",
       "      <td>0.673181</td>\n",
       "      <td>0.552227</td>\n",
       "      <td>2.505279</td>\n",
       "      <td>0.935454</td>\n",
       "      <td>-1.757434</td>\n",
       "      <td>0.622283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067170</td>\n",
       "      <td>-0.039249</td>\n",
       "      <td>-0.025862</td>\n",
       "      <td>-0.136603</td>\n",
       "      <td>-0.034412</td>\n",
       "      <td>-0.141647</td>\n",
       "      <td>-0.099841</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>-0.010625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.246736</td>\n",
       "      <td>-0.982296</td>\n",
       "      <td>-1.058335</td>\n",
       "      <td>3.200198</td>\n",
       "      <td>-2.305979</td>\n",
       "      <td>-0.932428</td>\n",
       "      <td>-1.015563</td>\n",
       "      <td>1.494617</td>\n",
       "      <td>-0.740410</td>\n",
       "      <td>0.086611</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052078</td>\n",
       "      <td>0.025125</td>\n",
       "      <td>-0.044625</td>\n",
       "      <td>0.030148</td>\n",
       "      <td>0.062255</td>\n",
       "      <td>-0.083018</td>\n",
       "      <td>-0.154070</td>\n",
       "      <td>-0.086774</td>\n",
       "      <td>-0.038711</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>-34.895940</td>\n",
       "      <td>12.944045</td>\n",
       "      <td>1.870205</td>\n",
       "      <td>-3.831495</td>\n",
       "      <td>0.686619</td>\n",
       "      <td>6.541515</td>\n",
       "      <td>-0.837515</td>\n",
       "      <td>2.598469</td>\n",
       "      <td>0.890204</td>\n",
       "      <td>-0.386867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.106738</td>\n",
       "      <td>-0.018222</td>\n",
       "      <td>-0.056227</td>\n",
       "      <td>0.045139</td>\n",
       "      <td>-0.073726</td>\n",
       "      <td>0.118520</td>\n",
       "      <td>0.284093</td>\n",
       "      <td>-0.055235</td>\n",
       "      <td>-0.139992</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>-22.136756</td>\n",
       "      <td>7.085892</td>\n",
       "      <td>1.208031</td>\n",
       "      <td>-3.264805</td>\n",
       "      <td>-1.908172</td>\n",
       "      <td>-0.903965</td>\n",
       "      <td>0.466233</td>\n",
       "      <td>0.407216</td>\n",
       "      <td>0.138196</td>\n",
       "      <td>1.588258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035915</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>-0.031155</td>\n",
       "      <td>0.038486</td>\n",
       "      <td>0.096514</td>\n",
       "      <td>-0.004047</td>\n",
       "      <td>0.104522</td>\n",
       "      <td>0.001722</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>36.842536</td>\n",
       "      <td>0.132218</td>\n",
       "      <td>1.842788</td>\n",
       "      <td>1.168576</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>0.848363</td>\n",
       "      <td>0.126983</td>\n",
       "      <td>0.088348</td>\n",
       "      <td>0.426385</td>\n",
       "      <td>-0.631720</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073506</td>\n",
       "      <td>0.044974</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>-0.083558</td>\n",
       "      <td>-0.015885</td>\n",
       "      <td>0.060331</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>-0.043172</td>\n",
       "      <td>-0.010070</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>-0.610027</td>\n",
       "      <td>-0.917198</td>\n",
       "      <td>0.134306</td>\n",
       "      <td>1.755179</td>\n",
       "      <td>-1.212960</td>\n",
       "      <td>-0.709465</td>\n",
       "      <td>0.853208</td>\n",
       "      <td>-0.115119</td>\n",
       "      <td>-0.337513</td>\n",
       "      <td>0.544065</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037394</td>\n",
       "      <td>0.031980</td>\n",
       "      <td>0.122400</td>\n",
       "      <td>0.008324</td>\n",
       "      <td>-0.091420</td>\n",
       "      <td>-0.014140</td>\n",
       "      <td>-0.025499</td>\n",
       "      <td>0.078796</td>\n",
       "      <td>-0.052277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>-15.356204</td>\n",
       "      <td>2.300814</td>\n",
       "      <td>-1.162025</td>\n",
       "      <td>-0.020442</td>\n",
       "      <td>1.981179</td>\n",
       "      <td>-2.791437</td>\n",
       "      <td>1.482743</td>\n",
       "      <td>0.287696</td>\n",
       "      <td>0.644070</td>\n",
       "      <td>-1.275425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059020</td>\n",
       "      <td>-0.083579</td>\n",
       "      <td>-0.018925</td>\n",
       "      <td>0.020212</td>\n",
       "      <td>-0.110133</td>\n",
       "      <td>0.042387</td>\n",
       "      <td>-0.030141</td>\n",
       "      <td>-0.059072</td>\n",
       "      <td>-0.185614</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          1         2         3         4         5         6  \\\n",
       "0   -16.679750   6.610424  1.136733 -1.577995  0.941055 -3.025814 -1.121022   \n",
       "1   -23.458153  -1.462552  0.568286  0.682060  2.939810  1.185212  0.878989   \n",
       "2   -26.483531  -1.381947 -5.211168 -0.556892  1.478389  0.592714 -0.714275   \n",
       "3   -15.449717  -1.581954  2.722015  3.208696  0.673181  0.552227  2.505279   \n",
       "4    -2.246736  -0.982296 -1.058335  3.200198 -2.305979 -0.932428 -1.015563   \n",
       "..         ...        ...       ...       ...       ...       ...       ...   \n",
       "795 -34.895940  12.944045  1.870205 -3.831495  0.686619  6.541515 -0.837515   \n",
       "796 -22.136756   7.085892  1.208031 -3.264805 -1.908172 -0.903965  0.466233   \n",
       "797  36.842536   0.132218  1.842788  1.168576  0.009397  0.848363  0.126983   \n",
       "798  -0.610027  -0.917198  0.134306  1.755179 -1.212960 -0.709465  0.853208   \n",
       "799 -15.356204   2.300814 -1.162025 -0.020442  1.981179 -2.791437  1.482743   \n",
       "\n",
       "            7         8         9  ...        91        92        93  \\\n",
       "0    2.277669 -0.086481  0.151895  ...  0.003830 -0.008588  0.004384   \n",
       "1    0.180153  1.651810  1.065205  ...  0.029080  0.092626 -0.011072   \n",
       "2    1.184789 -1.722228 -0.758348  ... -0.116402 -0.028197  0.288280   \n",
       "3    0.935454 -1.757434  0.622283  ...  0.067170 -0.039249 -0.025862   \n",
       "4    1.494617 -0.740410  0.086611  ... -0.052078  0.025125 -0.044625   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "795  2.598469  0.890204 -0.386867  ...  0.106738 -0.018222 -0.056227   \n",
       "796  0.407216  0.138196  1.588258  ... -0.035915  0.001172 -0.031155   \n",
       "797  0.088348  0.426385 -0.631720  ... -0.073506  0.044974  0.007108   \n",
       "798 -0.115119 -0.337513  0.544065  ... -0.037394  0.031980  0.122400   \n",
       "799  0.287696  0.644070 -1.275425  ...  0.059020 -0.083579 -0.018925   \n",
       "\n",
       "           94        95        96        97        98        99  Y  \n",
       "0   -0.079178  0.063324  0.101782  0.006377  0.034211  0.022819  0  \n",
       "1   -0.094988  0.163561 -0.030005  0.168839  0.143847  0.098675  0  \n",
       "2    0.067875  0.111195 -0.101227  0.089442 -0.193335  0.005820  0  \n",
       "3   -0.136603 -0.034412 -0.141647 -0.099841  0.012270 -0.010625  0  \n",
       "4    0.030148  0.062255 -0.083018 -0.154070 -0.086774 -0.038711  0  \n",
       "..        ...       ...       ...       ...       ...       ... ..  \n",
       "795  0.045139 -0.073726  0.118520  0.284093 -0.055235 -0.139992  0  \n",
       "796  0.038486  0.096514 -0.004047  0.104522  0.001722 -0.036679  0  \n",
       "797 -0.083558 -0.015885  0.060331  0.010884 -0.043172 -0.010070  0  \n",
       "798  0.008324 -0.091420 -0.014140 -0.025499  0.078796 -0.052277  0  \n",
       "799  0.020212 -0.110133  0.042387 -0.030141 -0.059072 -0.185614  1  \n",
       "\n",
       "[800 rows x 101 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2006d91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.596660</td>\n",
       "      <td>3.447911</td>\n",
       "      <td>0.685060</td>\n",
       "      <td>-0.972829</td>\n",
       "      <td>0.586031</td>\n",
       "      <td>0.084613</td>\n",
       "      <td>1.253618</td>\n",
       "      <td>0.973895</td>\n",
       "      <td>0.602800</td>\n",
       "      <td>-0.827459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.124348</td>\n",
       "      <td>-0.069717</td>\n",
       "      <td>-0.101251</td>\n",
       "      <td>-0.013494</td>\n",
       "      <td>-0.025994</td>\n",
       "      <td>0.050798</td>\n",
       "      <td>-0.060443</td>\n",
       "      <td>-0.050667</td>\n",
       "      <td>0.037390</td>\n",
       "      <td>-0.010210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-12.468571</td>\n",
       "      <td>4.096737</td>\n",
       "      <td>2.157081</td>\n",
       "      <td>2.838603</td>\n",
       "      <td>2.694191</td>\n",
       "      <td>0.791608</td>\n",
       "      <td>0.772297</td>\n",
       "      <td>-1.368098</td>\n",
       "      <td>-0.783070</td>\n",
       "      <td>-0.214776</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.044115</td>\n",
       "      <td>0.231198</td>\n",
       "      <td>-0.098698</td>\n",
       "      <td>0.136392</td>\n",
       "      <td>-0.269352</td>\n",
       "      <td>0.124734</td>\n",
       "      <td>-0.132256</td>\n",
       "      <td>0.056936</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.070021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.936250</td>\n",
       "      <td>3.968226</td>\n",
       "      <td>-0.089297</td>\n",
       "      <td>-0.170491</td>\n",
       "      <td>0.125510</td>\n",
       "      <td>-0.009929</td>\n",
       "      <td>-0.338571</td>\n",
       "      <td>-0.696645</td>\n",
       "      <td>-0.074221</td>\n",
       "      <td>0.200092</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020004</td>\n",
       "      <td>-0.135851</td>\n",
       "      <td>-0.076427</td>\n",
       "      <td>-0.024751</td>\n",
       "      <td>0.079515</td>\n",
       "      <td>0.070363</td>\n",
       "      <td>-0.129447</td>\n",
       "      <td>0.026875</td>\n",
       "      <td>0.069644</td>\n",
       "      <td>0.024132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-12.105856</td>\n",
       "      <td>-7.285071</td>\n",
       "      <td>-1.255603</td>\n",
       "      <td>-2.083037</td>\n",
       "      <td>0.823560</td>\n",
       "      <td>-2.782607</td>\n",
       "      <td>0.710146</td>\n",
       "      <td>0.964285</td>\n",
       "      <td>-0.941001</td>\n",
       "      <td>0.317748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.093660</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>0.062805</td>\n",
       "      <td>-0.061309</td>\n",
       "      <td>-0.105786</td>\n",
       "      <td>0.062776</td>\n",
       "      <td>0.016001</td>\n",
       "      <td>0.034753</td>\n",
       "      <td>-0.109254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-21.205216</td>\n",
       "      <td>3.286836</td>\n",
       "      <td>4.087839</td>\n",
       "      <td>-0.648757</td>\n",
       "      <td>-2.537696</td>\n",
       "      <td>2.648703</td>\n",
       "      <td>2.741293</td>\n",
       "      <td>2.422854</td>\n",
       "      <td>-0.570188</td>\n",
       "      <td>-0.571220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113444</td>\n",
       "      <td>0.239178</td>\n",
       "      <td>0.144884</td>\n",
       "      <td>0.226596</td>\n",
       "      <td>0.190667</td>\n",
       "      <td>-0.033776</td>\n",
       "      <td>-0.137122</td>\n",
       "      <td>-0.033199</td>\n",
       "      <td>0.094279</td>\n",
       "      <td>-0.121717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>-13.408361</td>\n",
       "      <td>-3.894930</td>\n",
       "      <td>0.705863</td>\n",
       "      <td>2.884851</td>\n",
       "      <td>0.652111</td>\n",
       "      <td>-0.698317</td>\n",
       "      <td>0.797878</td>\n",
       "      <td>-0.543348</td>\n",
       "      <td>1.489810</td>\n",
       "      <td>1.431270</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.023232</td>\n",
       "      <td>0.060630</td>\n",
       "      <td>0.028142</td>\n",
       "      <td>0.207512</td>\n",
       "      <td>0.013736</td>\n",
       "      <td>0.024744</td>\n",
       "      <td>-0.137786</td>\n",
       "      <td>0.179704</td>\n",
       "      <td>0.089591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>-12.246320</td>\n",
       "      <td>-5.184787</td>\n",
       "      <td>-2.696742</td>\n",
       "      <td>2.258510</td>\n",
       "      <td>0.441794</td>\n",
       "      <td>-1.121964</td>\n",
       "      <td>-1.093165</td>\n",
       "      <td>0.075793</td>\n",
       "      <td>1.564370</td>\n",
       "      <td>0.135477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059952</td>\n",
       "      <td>-0.066834</td>\n",
       "      <td>-0.102340</td>\n",
       "      <td>-0.042466</td>\n",
       "      <td>0.043799</td>\n",
       "      <td>-0.038101</td>\n",
       "      <td>0.092371</td>\n",
       "      <td>0.050095</td>\n",
       "      <td>-0.041916</td>\n",
       "      <td>-0.064044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>-13.938667</td>\n",
       "      <td>-3.853143</td>\n",
       "      <td>-0.689313</td>\n",
       "      <td>4.263422</td>\n",
       "      <td>-0.388860</td>\n",
       "      <td>0.676945</td>\n",
       "      <td>-0.165916</td>\n",
       "      <td>-0.175899</td>\n",
       "      <td>-0.544762</td>\n",
       "      <td>-1.451606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057601</td>\n",
       "      <td>0.131357</td>\n",
       "      <td>-0.141610</td>\n",
       "      <td>0.002946</td>\n",
       "      <td>0.081733</td>\n",
       "      <td>0.029722</td>\n",
       "      <td>-0.066150</td>\n",
       "      <td>-0.135012</td>\n",
       "      <td>-0.115422</td>\n",
       "      <td>0.070190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>23.985077</td>\n",
       "      <td>-5.587592</td>\n",
       "      <td>3.041282</td>\n",
       "      <td>0.720790</td>\n",
       "      <td>0.106822</td>\n",
       "      <td>0.972425</td>\n",
       "      <td>0.132087</td>\n",
       "      <td>-0.612798</td>\n",
       "      <td>0.210735</td>\n",
       "      <td>0.676083</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046005</td>\n",
       "      <td>-0.001896</td>\n",
       "      <td>-0.101255</td>\n",
       "      <td>0.041208</td>\n",
       "      <td>-0.132726</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>-0.016381</td>\n",
       "      <td>0.116176</td>\n",
       "      <td>0.049014</td>\n",
       "      <td>-0.010696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>-23.675058</td>\n",
       "      <td>-1.839045</td>\n",
       "      <td>-6.105015</td>\n",
       "      <td>-0.095203</td>\n",
       "      <td>-2.924020</td>\n",
       "      <td>0.119851</td>\n",
       "      <td>-4.166649</td>\n",
       "      <td>-1.349492</td>\n",
       "      <td>0.265547</td>\n",
       "      <td>-1.418552</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054279</td>\n",
       "      <td>0.032405</td>\n",
       "      <td>-0.064953</td>\n",
       "      <td>-0.244659</td>\n",
       "      <td>0.065381</td>\n",
       "      <td>-0.176782</td>\n",
       "      <td>-0.032879</td>\n",
       "      <td>-0.072379</td>\n",
       "      <td>-0.048326</td>\n",
       "      <td>0.066073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0     0.596660  3.447911  0.685060 -0.972829  0.586031  0.084613  1.253618   \n",
       "1   -12.468571  4.096737  2.157081  2.838603  2.694191  0.791608  0.772297   \n",
       "2    36.936250  3.968226 -0.089297 -0.170491  0.125510 -0.009929 -0.338571   \n",
       "3   -12.105856 -7.285071 -1.255603 -2.083037  0.823560 -2.782607  0.710146   \n",
       "4   -21.205216  3.286836  4.087839 -0.648757 -2.537696  2.648703  2.741293   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "345 -13.408361 -3.894930  0.705863  2.884851  0.652111 -0.698317  0.797878   \n",
       "346 -12.246320 -5.184787 -2.696742  2.258510  0.441794 -1.121964 -1.093165   \n",
       "347 -13.938667 -3.853143 -0.689313  4.263422 -0.388860  0.676945 -0.165916   \n",
       "348  23.985077 -5.587592  3.041282  0.720790  0.106822  0.972425  0.132087   \n",
       "349 -23.675058 -1.839045 -6.105015 -0.095203 -2.924020  0.119851 -4.166649   \n",
       "\n",
       "           7         8         9   ...        90        91        92  \\\n",
       "0    0.973895  0.602800 -0.827459  ...  0.124348 -0.069717 -0.101251   \n",
       "1   -1.368098 -0.783070 -0.214776  ... -0.044115  0.231198 -0.098698   \n",
       "2   -0.696645 -0.074221  0.200092  ... -0.020004 -0.135851 -0.076427   \n",
       "3    0.964285 -0.941001  0.317748  ... -0.093660  0.043956  0.004140   \n",
       "4    2.422854 -0.570188 -0.571220  ...  0.113444  0.239178  0.144884   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "345 -0.543348  1.489810  1.431270  ...  0.000575  0.023232  0.060630   \n",
       "346  0.075793  1.564370  0.135477  ...  0.059952 -0.066834 -0.102340   \n",
       "347 -0.175899 -0.544762 -1.451606  ... -0.057601  0.131357 -0.141610   \n",
       "348 -0.612798  0.210735  0.676083  ...  0.046005 -0.001896 -0.101255   \n",
       "349 -1.349492  0.265547 -1.418552  ... -0.054279  0.032405 -0.064953   \n",
       "\n",
       "           93        94        95        96        97        98        99  \n",
       "0   -0.013494 -0.025994  0.050798 -0.060443 -0.050667  0.037390 -0.010210  \n",
       "1    0.136392 -0.269352  0.124734 -0.132256  0.056936  0.015873  0.070021  \n",
       "2   -0.024751  0.079515  0.070363 -0.129447  0.026875  0.069644  0.024132  \n",
       "3    0.062805 -0.061309 -0.105786  0.062776  0.016001  0.034753 -0.109254  \n",
       "4    0.226596  0.190667 -0.033776 -0.137122 -0.033199  0.094279 -0.121717  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "345  0.028142  0.207512  0.013736  0.024744 -0.137786  0.179704  0.089591  \n",
       "346 -0.042466  0.043799 -0.038101  0.092371  0.050095 -0.041916 -0.064044  \n",
       "347  0.002946  0.081733  0.029722 -0.066150 -0.135012 -0.115422  0.070190  \n",
       "348  0.041208 -0.132726  0.007395 -0.016381  0.116176  0.049014 -0.010696  \n",
       "349 -0.244659  0.065381 -0.176782 -0.032879 -0.072379 -0.048326  0.066073  \n",
       "\n",
       "[350 rows x 100 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_F = pd.DataFrame(test_pca[:,:100])\n",
    "test_F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ab8546",
   "metadata": {},
   "source": [
    "#  Spliting into Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fbec291",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_F.iloc[:,:100]\n",
    "y_train = train_F.iloc[:,-1]\n",
    "x_test = test_F\n",
    "y_test_df = pd.read_csv('Y.csv',header=None)\n",
    "y_test = y_test_df.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9ca29ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "345  0\n",
       "346  1\n",
       "347  0\n",
       "348  0\n",
       "349  0\n",
       "\n",
       "[350 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58ec4d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 100), (800,), (350, 100), (350, 1))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape,x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e91ebdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    722\n",
       "1     78\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() # the data is highly im balanced "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3663205",
   "metadata": {},
   "source": [
    "# Resampling train data using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91444595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1c8df4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=9)\n",
    "x_train_sm,y_train_sm = sm.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "661e7d80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    722\n",
       "1    722\n",
       "Name: Y, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_sm.value_counts() # Imbalanced data is been handeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7f50ce45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1444, 100), (1444,), (350, 100), (350, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_sm.shape,y_train_sm.shape,x_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2874aff7",
   "metadata": {},
   "source": [
    "Our Data is Balanced and Ready for the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d36158",
   "metadata": {},
   "source": [
    "# Step-3: Model Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16b20bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all the models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Evaluation libraries\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
    "from sklearn.metrics import roc_curve,roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddb394b",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "78ac04fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;max_iter&#x27;: [100, 500, 1000, 1500, 2000],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;random_state&#x27;: [8]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;max_iter&#x27;: [100, 500, 1000, 1500, 2000],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;],\n",
       "                         &#x27;random_state&#x27;: [8]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(),\n",
       "             param_grid={'max_iter': [100, 500, 1000, 1500, 2000],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet'],\n",
       "                         'random_state': [8]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model=LogisticRegression()\n",
    "grid_params={'penalty':['l1', 'l2', 'elasticnet'],'max_iter':[100,500,1000,1500,2000],'random_state':[8]}\n",
    "grid=GridSearchCV(lr_model,grid_params,cv=10,scoring='accuracy')\n",
    "grid.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fb4231b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is:  0.8109195402298852\n",
      "The best Parameters are:  {'max_iter': 500, 'penalty': 'l2', 'random_state': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best score is: \",grid.best_score_)\n",
    "print(\"The best Parameters are: \",grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "17182210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy for logistic regression model is:  79.98614958448753\n"
     ]
    }
   ],
   "source": [
    "# Creating model using the best params\n",
    "lr_model=LogisticRegression(penalty='l2',max_iter=1000,solver='saga',random_state=8)\n",
    "lr_model.fit(x_train_sm,y_train_sm)\n",
    "lr_train_pred=lr_model.predict(x_train_sm)\n",
    "lr_acc=accuracy_score(y_train_sm,lr_train_pred)*100\n",
    "print(\"The training accuracy for logistic regression model is: \",lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ed81488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.74      0.79       722\n",
      "           1       0.77      0.86      0.81       722\n",
      "\n",
      "    accuracy                           0.80      1444\n",
      "   macro avg       0.80      0.80      0.80      1444\n",
      "weighted avg       0.80      0.80      0.80      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for training data\n",
    "print(classification_report(y_train_sm,lr_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27f8640",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6443f3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4, 5, 6, 7, 8],\n",
       "                         &#x27;random_state&#x27;: [8]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 4, 5, 6, 7, 8],\n",
       "                         &#x27;random_state&#x27;: [8]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'min_samples_split': [2, 4, 5, 6, 7, 8],\n",
       "                         'random_state': [8]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model=DecisionTreeClassifier()\n",
    "grid_params={'criterion':['gini','entropy','log_loss'],'min_samples_split':[2,4,5,6,7,8],'random_state':[8]}\n",
    "grid=GridSearchCV(dt_model,grid_params,cv=10,scoring='accuracy')\n",
    "grid.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bda71c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is:  0.8850383141762453\n",
      "The best Parameters are:  {'criterion': 'entropy', 'min_samples_split': 2, 'random_state': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best score is: \",grid.best_score_)\n",
    "print(\"The best Parameters are: \",grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8692c05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy for decision tree model is:  100.0\n"
     ]
    }
   ],
   "source": [
    "# Creating model using the best params\n",
    "dt_model=DecisionTreeClassifier(criterion='entropy',min_samples_split=2,random_state=8)\n",
    "dt_model.fit(x_train_sm,y_train_sm)\n",
    "dt_train_pred=dt_model.predict(x_train_sm)\n",
    "dt_acc=accuracy_score(y_train_sm,dt_train_pred)*100\n",
    "print(\"The training accuracy for decision tree model is: \",dt_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "63dda197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       722\n",
      "\n",
      "    accuracy                           1.00      1444\n",
      "   macro avg       1.00      1.00      1.00      1444\n",
      "weighted avg       1.00      1.00      1.00      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for training data\n",
    "print(classification_report(y_train_sm,dt_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5f0a34",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6cb9cb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 6, 7],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 50, 100],\n",
       "                         &#x27;random_state&#x27;: [8]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;, &#x27;log_loss&#x27;],\n",
       "                         &#x27;max_features&#x27;: [&#x27;sqrt&#x27;, &#x27;log2&#x27;],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 6, 7],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 50, 100],\n",
       "                         &#x27;random_state&#x27;: [8]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy', 'log_loss'],\n",
       "                         'max_features': ['sqrt', 'log2'],\n",
       "                         'min_samples_split': [2, 5, 6, 7],\n",
       "                         'n_estimators': [10, 20, 50, 100],\n",
       "                         'random_state': [8]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model=RandomForestClassifier()\n",
    "grid_params={'n_estimators':[10,20,50,100],'criterion':['gini','entropy','log_loss'],'min_samples_split':[2,5,6,7],'max_features':[\"sqrt\", \"log2\"],'random_state':[8]}\n",
    "grid=GridSearchCV(rf_model,grid_params,cv=10,scoring='accuracy')\n",
    "grid.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d70d703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is:  0.9075000000000001\n",
      "The best Parameters are:  {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_split': 5, 'n_estimators': 50, 'random_state': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best score is: \",grid.best_score_)\n",
    "print(\"The best Parameters are: \",grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "63fba9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy for random forest model is:  96.625\n"
     ]
    }
   ],
   "source": [
    "# Creating model using the best params\n",
    "rf_model=RandomForestClassifier(criterion='gini',max_features='sqrt', min_samples_split=5, n_estimators=10,random_state=8)\n",
    "rf_model.fit(x_train,y_train)\n",
    "rf_train_pred=rf_model.predict(x_train)\n",
    "rf_acc=accuracy_score(y_train,rf_train_pred)*100\n",
    "print(\"The training accuracy for random forest model is: \",rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e854558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       722\n",
      "           1       1.00      0.65      0.79        78\n",
      "\n",
      "    accuracy                           0.97       800\n",
      "   macro avg       0.98      0.83      0.89       800\n",
      "weighted avg       0.97      0.97      0.96       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,rf_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483d43db",
   "metadata": {},
   "source": [
    "### Naive - Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b123d7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy for logistic regression model is:  81.85595567867036\n"
     ]
    }
   ],
   "source": [
    "nb_model=GaussianNB()\n",
    "nb_model.fit(x_train_sm,y_train_sm)\n",
    "nb_train_pred=nb_model.predict(x_train_sm)\n",
    "nb_acc=accuracy_score(y_train_sm,nb_train_pred)*100\n",
    "print(\"The training accuracy for logistic regression model is: \",nb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b658ec6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.80      0.81       722\n",
      "           1       0.81      0.84      0.82       722\n",
      "\n",
      "    accuracy                           0.82      1444\n",
      "   macro avg       0.82      0.82      0.82      1444\n",
      "weighted avg       0.82      0.82      0.82      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for training data\n",
    "print(classification_report(y_train_sm,nb_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d901e2",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c9cf323a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=Perceptron(),\n",
       "             param_grid={&#x27;eta0&#x27;: [10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;random_state&#x27;: [8]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=Perceptron(),\n",
       "             param_grid={&#x27;eta0&#x27;: [10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;random_state&#x27;: [8]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Perceptron(),\n",
       "             param_grid={'eta0': [10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'random_state': [8]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_model=Perceptron()\n",
    "grid_params={'eta0':[10,1,0.1,0.01,0.001,0.0001],'random_state':[8]}\n",
    "grid=GridSearchCV(pr_model,grid_params,cv=10,scoring='accuracy')\n",
    "grid.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b1eaf06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is:  0.6807040229885059\n",
      "The best Parameters are:  {'eta0': 0.001, 'random_state': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best score is: \",grid.best_score_)\n",
    "print(\"The best Parameters are: \",grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c44f6d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy for logistic regression model is:  69.11357340720221\n"
     ]
    }
   ],
   "source": [
    "# Creating model using the best params\n",
    "pr_model=Perceptron(eta0=10,random_state=8)\n",
    "pr_model.fit(x_train_sm,y_train_sm)\n",
    "pr_train_pred=pr_model.predict(x_train_sm)\n",
    "pr_acc=accuracy_score(y_train_sm,pr_train_pred)*100\n",
    "print(\"The training accuracy for logistic regression model is: \",pr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "44562cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.75      0.71       722\n",
      "           1       0.72      0.63      0.67       722\n",
      "\n",
      "    accuracy                           0.69      1444\n",
      "   macro avg       0.69      0.69      0.69      1444\n",
      "weighted avg       0.69      0.69      0.69      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for training data\n",
    "print(classification_report(y_train_sm,pr_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781d68ab",
   "metadata": {},
   "source": [
    "### K - Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4c6cbb72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={&#x27;n_neighbors&#x27;: [2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': [2, 3, 4, 5, 6, 7, 8, 9]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model=KNeighborsClassifier()\n",
    "grid_params={'n_neighbors':[2,3,4,5,6,7,8,9]}\n",
    "grid=GridSearchCV(knn_model,grid_params,cv=10,scoring='accuracy')\n",
    "grid.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19a1900c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is:  0.8781417624521073\n",
      "The best Parameters are:  {'n_neighbors': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best score is: \",grid.best_score_)\n",
    "print(\"The best Parameters are: \",grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9611f9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy for logistic regression model is:  99.79224376731301\n"
     ]
    }
   ],
   "source": [
    "# Creating model using the best params\n",
    "knn_model=KNeighborsClassifier(n_neighbors=2)\n",
    "knn_model.fit(x_train_sm,y_train_sm)\n",
    "knn_train_pred=knn_model.predict(x_train_sm)\n",
    "knn_acc=accuracy_score(y_train_sm,knn_train_pred)*100\n",
    "print(\"The training accuracy for logistic regression model is: \",knn_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a17c4629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       722\n",
      "\n",
      "    accuracy                           1.00      1444\n",
      "   macro avg       1.00      1.00      1.00      1444\n",
      "weighted avg       1.00      1.00      1.00      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for training data\n",
    "print(classification_report(y_train_sm,knn_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b9661",
   "metadata": {},
   "source": [
    "### Support Vector Machining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "daf29382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 3, 5, 7, 9, 11],\n",
       "                         &#x27;gamma&#x27;: [10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;], &#x27;random_state&#x27;: [8]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [1, 3, 5, 7, 9, 11],\n",
       "                         &#x27;gamma&#x27;: [10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;], &#x27;random_state&#x27;: [8]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(),\n",
       "             param_grid={'C': [1, 3, 5, 7, 9, 11],\n",
       "                         'gamma': [10, 1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf'], 'random_state': [8]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model=SVC()\n",
    "grid_params={'kernel':['rbf'],'C':[1,3,5,7,9,11],'gamma':[10,1,0.1,0.01,0.001,0.0001],'random_state':[8]}\n",
    "grid=GridSearchCV(svc_model,grid_params,cv=10,scoring='accuracy')\n",
    "grid.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1781ca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score is:  0.9854501915708811\n",
      "The best Parameters are:  {'C': 5, 'gamma': 0.1, 'kernel': 'rbf', 'random_state': 8}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best score is: \",grid.best_score_)\n",
    "print(\"The best Parameters are: \",grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a28be5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy for logistic regression model is:  100.0\n"
     ]
    }
   ],
   "source": [
    "# Creating model using the best params\n",
    "svc_model=SVC(kernel='rbf',gamma=0.1,C=5,random_state=8)\n",
    "svc_model.fit(x_train_sm,y_train_sm)\n",
    "svc_train_pred=svc_model.predict(x_train_sm)\n",
    "svc_acc=accuracy_score(y_train_sm,svc_train_pred)*100\n",
    "print(\"The training accuracy for logistic regression model is: \",svc_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0e64c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       722\n",
      "           1       1.00      1.00      1.00       722\n",
      "\n",
      "    accuracy                           1.00      1444\n",
      "   macro avg       1.00      1.00      1.00      1444\n",
      "weighted avg       1.00      1.00      1.00      1444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification Report for training data\n",
    "print(classification_report(y_train_sm,svc_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2d7b41",
   "metadata": {},
   "source": [
    "### All Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b2c8961",
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame({'Models':['Decision Tree Classifier','Random Forest Classifier','Logistic Regression',\n",
    "                              'Naive Bayes','KNN','Perceptron','SVC'],\n",
    "                    'Train_Accuracy':[dt_acc,rf_acc,lr_acc,nb_acc,knn_acc,pr_acc,svc_acc]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "84592462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Train_Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>99.792244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>96.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>81.855956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>79.986150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>69.113573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Models  Train_Accuracy\n",
       "0  Decision Tree Classifier      100.000000\n",
       "6                       SVC      100.000000\n",
       "4                       KNN       99.792244\n",
       "1  Random Forest Classifier       96.625000\n",
       "3               Naive Bayes       81.855956\n",
       "2       Logistic Regression       79.986150\n",
       "5                Perceptron       69.113573"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sort_values('Train_Accuracy',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ff95a1",
   "metadata": {},
   "source": [
    "# Step-4: Model Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff0b062",
   "metadata": {},
   "source": [
    "### We will evaluate all the models on the test data and based on the f1 score and AUC score, we will decide which one is the best fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad3bd3",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7aa5113b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_test_pred=lr_model.predict(x_test)\n",
    "accuracy_score(y_test,lr_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f204025b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.66      0.77       316\n",
      "           1       0.13      0.50      0.21        34\n",
      "\n",
      "    accuracy                           0.64       350\n",
      "   macro avg       0.53      0.58      0.49       350\n",
      "weighted avg       0.85      0.64      0.71       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,lr_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3db1d6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15bb11cfb80>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve for Logistic Regression model\n",
    "\n",
    "y_pred_6 = lr_model.predict_proba(x_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_6)\n",
    "auc = round(roc_auc_score(y_test, y_pred_6), 4)\n",
    "plt.plot(fpr,tpr,label=\"Logistic Regression, AUC=\"+str(auc))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129878fd",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "50d7f4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085714285714286"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_test_pred=dt_model.predict(x_test)\n",
    "accuracy_score(y_test,dt_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "089170c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89       316\n",
      "           1       0.22      0.38      0.28        34\n",
      "\n",
      "    accuracy                           0.81       350\n",
      "   macro avg       0.57      0.62      0.58       350\n",
      "weighted avg       0.86      0.81      0.83       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,dt_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3a9e5266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15bb11c9730>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve for Decision Tree Classifier\n",
    "\n",
    "y_pred_7 = dt_model.predict_proba(x_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_7)\n",
    "auc = round(roc_auc_score(y_test, y_pred_7), 4)\n",
    "plt.plot(fpr,tpr,label=\"Decision Tree Classifier, AUC=\"+str(auc))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de81037",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "60948688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9028571428571428"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test_pred=rf_model.predict(x_test)\n",
    "accuracy_score(y_test,rf_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ef55b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95       316\n",
      "           1       0.50      0.03      0.06        34\n",
      "\n",
      "    accuracy                           0.90       350\n",
      "   macro avg       0.70      0.51      0.50       350\n",
      "weighted avg       0.87      0.90      0.86       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,rf_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1b602b5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15bb0b8e310>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC Curve for Random Forest Model\n",
    "from sklearn.metrics import roc_curve,roc_auc_score\n",
    "\n",
    "y_pred_1 = rf_model.predict_proba(x_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_1)\n",
    "auc = round(roc_auc_score(y_test, y_pred_1), 4)\n",
    "plt.plot(fpr,tpr,label=\"Random Forest, AUC=\"+str(auc))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e036d4aa",
   "metadata": {},
   "source": [
    "### Naive - Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8b046066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7342857142857143"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_test_pred=nb_model.predict(x_test)\n",
    "accuracy_score(y_test,nb_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b286ddd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.76      0.84       316\n",
      "           1       0.18      0.50      0.27        34\n",
      "\n",
      "    accuracy                           0.73       350\n",
      "   macro avg       0.56      0.63      0.55       350\n",
      "weighted avg       0.86      0.73      0.78       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,nb_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "76e6c6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15bb27d8490>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC Curve for Naive Bayes Model\n",
    "\n",
    "y_pred_3 = nb_model.predict_proba(x_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_3)\n",
    "auc = round(roc_auc_score(y_test, y_pred_3), 4)\n",
    "plt.plot(fpr,tpr,label=\"Naive Bayes, AUC=\"+str(auc))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a9e3a",
   "metadata": {},
   "source": [
    "### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8432d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6285714285714286"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_test_pred=pr_model.predict(x_test)\n",
    "accuracy_score(y_test,pr_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "67768cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.66      0.76       316\n",
      "           1       0.10      0.35      0.16        34\n",
      "\n",
      "    accuracy                           0.63       350\n",
      "   macro avg       0.50      0.51      0.46       350\n",
      "weighted avg       0.83      0.63      0.70       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pr_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4699dd3f",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "df9e0759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_test_pred=knn_model.predict(x_test)\n",
    "accuracy_score(y_test,knn_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3cd5e663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.75      0.82       316\n",
      "           1       0.10      0.26      0.15        34\n",
      "\n",
      "    accuracy                           0.70       350\n",
      "   macro avg       0.50      0.51      0.48       350\n",
      "weighted avg       0.83      0.70      0.75       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,knn_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c08495f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15bb27b7640>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve for KNN model\n",
    "\n",
    "y_pred_5 = knn_model.predict_proba(x_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_5)\n",
    "auc = round(roc_auc_score(y_test, y_pred_5), 4)\n",
    "plt.plot(fpr,tpr,label=\"Support Vector Classifier, AUC=\"+str(auc))\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9134f309",
   "metadata": {},
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3ef29d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8857142857142857"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_test_pred=svc_model.predict(x_test)\n",
    "accuracy_score(y_test,svc_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "75caad68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       316\n",
      "           1       0.12      0.03      0.05        34\n",
      "\n",
      "    accuracy                           0.89       350\n",
      "   macro avg       0.51      0.50      0.49       350\n",
      "weighted avg       0.83      0.89      0.85       350\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,svc_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf75f786",
   "metadata": {},
   "source": [
    "# F1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ae6b4b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1 score for all models (macro avg)\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_lr=f1_score(y_test,lr_test_pred,average='macro')\n",
    "f1_dt=f1_score(y_test,dt_test_pred,average='macro')\n",
    "f1_rf=f1_score(y_test,rf_test_pred,average='macro')\n",
    "f1_nb=f1_score(y_test,nb_test_pred,average='macro')\n",
    "f1_per=f1_score(y_test,pr_test_pred,average='macro')\n",
    "f1_knn=f1_score(y_test,knn_test_pred,average='macro')\n",
    "f1_svc=f1_score(y_test,svc_test_pred,average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c2c1fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores=pd.DataFrame({'Model':['Logistic Regression','Decision Tree','Randm Forest','Naive Bayes','Perceptron','KNN','SVC'],\n",
    "                        'f1_scores':[f1_lr,f1_dt,f1_rf,f1_nb,f1_per,f1_knn,f1_svc]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "25918a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>f1_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.584595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.552706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Randm Forest</td>\n",
       "      <td>0.502175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.493414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.489583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.482183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.458874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  f1_scores\n",
       "1        Decision Tree   0.584595\n",
       "3          Naive Bayes   0.552706\n",
       "2         Randm Forest   0.502175\n",
       "6                  SVC   0.493414\n",
       "0  Logistic Regression   0.489583\n",
       "5                  KNN   0.482183\n",
       "4           Perceptron   0.458874"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores.sort_values(by='f1_scores',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df489b99",
   "metadata": {},
   "source": [
    "Decision Tree Classifier and Naive Bayes both are performing well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9b815",
   "metadata": {},
   "source": [
    "# Step-5: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b934bd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ebe14cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, random_state=8)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, random_state=8)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model_final=DecisionTreeClassifier(criterion='entropy',min_samples_split=2,random_state=8)\n",
    "dt_model_final.fit(x_train_sm,y_train_sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b248b04",
   "metadata": {},
   "source": [
    "# Step-6: Model Deployment using streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c6fd7f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "from pickle import load\n",
    "\n",
    "dump(dt_model_final, open('dt.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f40a1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load(open('dt.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196b10e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run application.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8da53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
